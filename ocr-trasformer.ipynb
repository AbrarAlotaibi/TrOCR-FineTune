{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c56fff9bdb28461e9193e135d169e807":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e8ef4e82bbd41ababdf2c759b6e8503","IPY_MODEL_ad38a5c2a96f4ae2a8b59960270656a5","IPY_MODEL_5f873d1292944b7ab8dc6326f4442a4b"],"layout":"IPY_MODEL_d6d424ab239046a6b78ae7b38fb0fec1"}},"8e8ef4e82bbd41ababdf2c759b6e8503":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ff2a93277874ce983c610315c1c668c","placeholder":"​","style":"IPY_MODEL_6e4c5fbb702d4bdda6836bc00d0ccd2c","value":"  0%"}},"ad38a5c2a96f4ae2a8b59960270656a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_964938feed44481d91290f6771f4e72d","max":280,"min":0,"orientation":"horizontal","style":"IPY_MODEL_927b088272ed482783f99309fe9aa8d3","value":0}},"5f873d1292944b7ab8dc6326f4442a4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_677eeb44627b47389f987a0564127f46","placeholder":"​","style":"IPY_MODEL_d9ebf86a5c754039b730c353c2b85044","value":" 0/280 [00:49&lt;?, ?it/s]"}},"d6d424ab239046a6b78ae7b38fb0fec1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ff2a93277874ce983c610315c1c668c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e4c5fbb702d4bdda6836bc00d0ccd2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"964938feed44481d91290f6771f4e72d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"927b088272ed482783f99309fe9aa8d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"677eeb44627b47389f987a0564127f46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9ebf86a5c754039b730c353c2b85044":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers\n!pip install -q datasets jiwer","metadata":{"id":"gnrlB0VWML4I","execution":{"iopub.status.busy":"2022-11-05T09:57:57.231157Z","iopub.execute_input":"2022-11-05T09:57:57.231567Z","iopub.status.idle":"2022-11-05T09:58:22.038695Z","shell.execute_reply.started":"2022-11-05T09:57:57.231446Z","shell.execute_reply":"2022-11-05T09:58:22.037497Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npython-levenshtein 0.20.7 requires Levenshtein==0.20.7, but you have levenshtein 0.20.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"no_deprecation_warning\"] =\"true\"","metadata":{"execution":{"iopub.status.busy":"2022-11-05T09:58:22.041605Z","iopub.execute_input":"2022-11-05T09:58:22.042004Z","iopub.status.idle":"2022-11-05T09:58:22.047757Z","shell.execute_reply.started":"2022-11-05T09:58:22.041965Z","shell.execute_reply":"2022-11-05T09:58:22.046710Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom transformers import TrOCRProcessor,VisionEncoderDecoderModel, AutoTokenizer, ViTFeatureExtractor, AutoModel\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom datasets import load_metric\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2022-11-05T09:58:22.049342Z","iopub.execute_input":"2022-11-05T09:58:22.050037Z","iopub.status.idle":"2022-11-05T09:58:25.480876Z","shell.execute_reply.started":"2022-11-05T09:58:22.050002Z","shell.execute_reply":"2022-11-05T09:58:25.479788Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Preparing data","metadata":{"id":"A2EdH-xDQ20K"}},{"cell_type":"markdown","source":"## Load Train Data","metadata":{"id":"5Ipuv10lTwXB"}},{"cell_type":"code","source":"df_t = pd.read_excel('../input/khattpilottest/KHATT-Pilot/Groundtruth-Unicode.xlsx',sheet_name=0,header=None)\ndf_t.rename(columns={0: \"file_name\", 1: \"text\"}, inplace=True)\ndf_t.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"T9t8xzfvJv1D","outputId":"16d5d0da-e91b-4974-9e8b-0f2c775c659a","execution":{"iopub.status.busy":"2022-11-05T09:58:25.482805Z","iopub.execute_input":"2022-11-05T09:58:25.483789Z","iopub.status.idle":"2022-11-05T09:58:25.837475Z","shell.execute_reply.started":"2022-11-05T09:58:25.483752Z","shell.execute_reply":"2022-11-05T09:58:25.836420Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                file_name                                               text\n0  AHTD3A0001_Para2_3.tif  من العذاب في الآخرة، وأفضل ما رزقهم الله تعالى...\n1  AHTD3A0001_Para2_4.tif  لجميع الأشياء والذي لا يقدر أحدٌ في الدنيا على...\n2  AHTD3A0001_Para3_1.tif  فقال له  إنك في منازل آبائك وأجدادك من الجبابر...\n3  AHTD3A0001_Para3_2.tif  قبلك، وشيدوه دونك، وبنوا القلاع والحصون، ومهدو...\n4  AHTD3A0002_Para2_1.tif  وكذلك طالب الآخرة مجتهد في العمل المنجي به روح...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AHTD3A0001_Para2_3.tif</td>\n      <td>من العذاب في الآخرة، وأفضل ما رزقهم الله تعالى...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AHTD3A0001_Para2_4.tif</td>\n      <td>لجميع الأشياء والذي لا يقدر أحدٌ في الدنيا على...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AHTD3A0001_Para3_1.tif</td>\n      <td>فقال له  إنك في منازل آبائك وأجدادك من الجبابر...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AHTD3A0001_Para3_2.tif</td>\n      <td>قبلك، وشيدوه دونك، وبنوا القلاع والحصون، ومهدو...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AHTD3A0002_Para2_1.tif</td>\n      <td>وكذلك طالب الآخرة مجتهد في العمل المنجي به روح...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Load Validation Data","metadata":{"id":"oXbTJoR5T20e"}},{"cell_type":"code","source":"df_v = pd.read_excel('../input/khattpilottest/KHATT-Pilot/Groundtruth-Unicode.xlsx',sheet_name=1,header=None)\ndf_v.rename(columns={0: \"file_name\", 1: \"text\"}, inplace=True)\ndf_v.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"SKe9hPi5P3CY","outputId":"d2f41b4b-c5ff-4173-b175-c5bdd1c58f4a","execution":{"iopub.status.busy":"2022-11-05T09:58:25.840903Z","iopub.execute_input":"2022-11-05T09:58:25.841394Z","iopub.status.idle":"2022-11-05T09:58:25.932466Z","shell.execute_reply.started":"2022-11-05T09:58:25.841355Z","shell.execute_reply":"2022-11-05T09:58:25.930593Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                file_name                                               text\n0  AHTD3A0438_Para3_4.tif  وقد كانت حرة نشطة عاشت أمدا طويلاّ كما يظهر من...\n1  AHTD3A0441_Para2_1.tif  وهي مساحات من الأرضين تعلوها رمال حمر في الغال...\n2  AHTD3A0441_Para2_2.tif  إلى حضرموت ومهرة في الجنوب، واليمن في الغرب، و...\n3  AHTD3A0441_Para2_3.tif  سلاسل من التلال الرملية ذات ارتفاعات مختلفة، ت...\n4  AHTD3A0441_Para2_4.tif  الرياح، وتغطي مساحات واسعة من الأرض  ويمكن الع...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AHTD3A0438_Para3_4.tif</td>\n      <td>وقد كانت حرة نشطة عاشت أمدا طويلاّ كما يظهر من...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AHTD3A0441_Para2_1.tif</td>\n      <td>وهي مساحات من الأرضين تعلوها رمال حمر في الغال...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AHTD3A0441_Para2_2.tif</td>\n      <td>إلى حضرموت ومهرة في الجنوب، واليمن في الغرب، و...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AHTD3A0441_Para2_3.tif</td>\n      <td>سلاسل من التلال الرملية ذات ارتفاعات مختلفة، ت...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AHTD3A0441_Para2_4.tif</td>\n      <td>الرياح، وتغطي مساحات واسعة من الأرض  ويمكن الع...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Create Data Tensors","metadata":{"id":"Gzd1PxUZT_f4"}},{"cell_type":"code","source":"class KHATDataset(Dataset):\n    def __init__(self, root_dir, df, processor, max_target_length=128):\n        self.root_dir = root_dir\n        self.df = df\n        self.processor = processor\n        self.max_target_length = max_target_length\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        # get file name + text \n        file_name = self.df['file_name'][idx]\n        text = self.df['text'][idx]\n        # prepare image (i.e. resize + normalize)\n        image = Image.open(self.root_dir + file_name).convert(\"RGB\")\n        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n        # add labels (input_ids) by encoding the text\n        labels = self.processor.tokenizer(text, \n                                          padding=\"max_length\",\n                                          truncation=True,\n                                          max_length=self.max_target_length).input_ids\n        # important: make sure that PAD tokens are ignored by the loss function\n        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n\n        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n        return encoding","metadata":{"id":"5roXQixDRu3v","execution":{"iopub.status.busy":"2022-11-05T09:58:25.934110Z","iopub.execute_input":"2022-11-05T09:58:25.934778Z","iopub.status.idle":"2022-11-05T09:58:25.945097Z","shell.execute_reply.started":"2022-11-05T09:58:25.934740Z","shell.execute_reply":"2022-11-05T09:58:25.944156Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabertv2\")\nfeature_extractor=ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\nprocessor = TrOCRProcessor(feature_extractor = feature_extractor, tokenizer = tokenizer)\ntrain_dataset = KHATDataset(root_dir='../input/khattpilottest/KHATT-Pilot/Line Images/Line Images/',\n                           df=df_t,\n                           processor=processor)\neval_dataset = KHATDataset(root_dir='../input/khattpilottest/KHATT-Pilot/Line Images/Line Images/',\n                           df=df_v,\n                           processor=processor)\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-11-05T09:58:25.948210Z","iopub.execute_input":"2022-11-05T09:58:25.948673Z","iopub.status.idle":"2022-11-05T09:58:43.621026Z","shell.execute_reply.started":"2022-11-05T09:58:25.948645Z","shell.execute_reply":"2022-11-05T09:58:43.620087Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/611 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3343e2667a649879d7f79bd9e06892a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/384 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8be8c779b6d248b0b122d0dbf95f6446"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/703k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b32dc780c7634e0b82c377e7a2404f53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.20M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10234a82197e4d92b191ecbf8b22fde0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d57189d50b14a1a974e2a70f1177e42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/160 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12a093dead5a4f6c876407df5531f635"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Correctness Check","metadata":{}},{"cell_type":"code","source":"print(\"Number of training examples:\", len(train_dataset))\nprint(\"Number of validation examples:\", len(eval_dataset))","metadata":{"id":"s6UC9_L_Sk6s","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a235d37e-664f-4dad-d462-6b4da8ca720a","execution":{"iopub.status.busy":"2022-11-05T09:58:43.622477Z","iopub.execute_input":"2022-11-05T09:58:43.623269Z","iopub.status.idle":"2022-11-05T09:58:43.629656Z","shell.execute_reply.started":"2022-11-05T09:58:43.623232Z","shell.execute_reply":"2022-11-05T09:58:43.628392Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Number of training examples: 1400\nNumber of validation examples: 233\n","output_type":"stream"}]},{"cell_type":"code","source":"encoding = train_dataset[0]\nfor k,v in encoding.items():\n  print(k, v.shape)\nencoding = eval_dataset[0]\nfor k,v in encoding.items():\n  print(k, v.shape)","metadata":{"id":"KOIeZHwPSowQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f60cb013-bd6f-40c9-e110-2d65753a2eb6","execution":{"iopub.status.busy":"2022-11-05T09:58:43.631290Z","iopub.execute_input":"2022-11-05T09:58:43.631933Z","iopub.status.idle":"2022-11-05T09:58:43.694567Z","shell.execute_reply.started":"2022-11-05T09:58:43.631898Z","shell.execute_reply":"2022-11-05T09:58:43.693544Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"pixel_values torch.Size([3, 224, 224])\nlabels torch.Size([128])\npixel_values torch.Size([3, 224, 224])\nlabels torch.Size([128])\n","output_type":"stream"}]},{"cell_type":"code","source":"image = Image.open(train_dataset.root_dir + df_v['file_name'][0]).convert(\"RGB\")\nimage","metadata":{"id":"v5uaJCF0TB4k","colab":{"base_uri":"https://localhost:8080/","height":130},"outputId":"00243f37-ee66-495c-8a0c-a4b5d78b1051","execution":{"iopub.status.busy":"2022-11-05T09:58:43.696242Z","iopub.execute_input":"2022-11-05T09:58:43.696662Z","iopub.status.idle":"2022-11-05T09:58:43.723024Z","shell.execute_reply.started":"2022-11-05T09:58:43.696622Z","shell.execute_reply":"2022-11-05T09:58:43.721951Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=2363x112>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"labels = encoding['labels']\nlabels[labels == -100] = processor.tokenizer.pad_token_id\nlabel_str = processor.decode(labels, skip_special_tokens=True)\nprint(label_str)\nprint(labels)","metadata":{"id":"jvpw3TVAXUxe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ddece153-d949-4bac-f07b-a47fd3668ef4","execution":{"iopub.status.busy":"2022-11-05T09:58:43.724708Z","iopub.execute_input":"2022-11-05T09:58:43.725096Z","iopub.status.idle":"2022-11-05T09:58:47.414490Z","shell.execute_reply.started":"2022-11-05T09:58:43.725058Z","shell.execute_reply":"2022-11-05T09:58:47.413539Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"وقد كانت حرة نشطة عاشت أمدا كما يظهر من وصف \" الهمداني \" وغيرها لها\ntensor([   33, 35216, 46656,   566,   251,  6892,   251,  3402,   210,  7529,\n          195,    32,   506,  3499,   290,  1790,    37, 21436, 23361,    37,\n        52159,  2331, 52578,    34,    31,    31,    31,    31,    31,    31,\n           31,    31,    31,    31,    31,    31,    31,    31,    31,    31,\n           31,    31,    31,    31,    31,    31,    31,    31,    31,    31,\n           31,    31,    31,    31,    31,    31,    31,    31,    31,    31,\n           31,    31,    31,    31,    31,    31,    31,    31,    31,    31,\n           31,    31,    31,    31,    31,    31,    31,    31,    31,    31,\n           31,    31,    31,    31,    31,    31,    31,    31,    31,    31,\n           31,    31,    31,    31,    31,    31,    31,    31,    31,    31,\n           31,    31,    31,    31,    31,    31,    31,    31,    31,    31,\n           31,    31,    31,    31,    31,    31,    31,    31,    31,    31,\n           31,    31,    31,    31,    31,    31,    31,    31])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Dataloader for Model","metadata":{"id":"FzLEzlRVXc21"}},{"cell_type":"code","source":"#train_dataloader = DataLoader(train_dataset, batch_size=8)\n#eval_dataloader = DataLoader(eval_dataset, batch_size=8)","metadata":{"id":"zYSxu_gtXh4R","execution":{"iopub.status.busy":"2022-11-05T09:58:47.415981Z","iopub.execute_input":"2022-11-05T09:58:47.416335Z","iopub.status.idle":"2022-11-05T09:58:47.422621Z","shell.execute_reply.started":"2022-11-05T09:58:47.416299Z","shell.execute_reply":"2022-11-05T09:58:47.421472Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{"id":"RnxtbH0aXl1X"}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# initialize the encoder from a pretrained ViT and the decoder from a pretrained BERT model. \n# Note that the cross-attention layers will be randomly initialized, and need to be fine-tuned on a downstream dataset\nmodel = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\"google/vit-base-patch16-224\", \"aubmindlab/bert-base-arabertv2\")\nprint(model.config.decoder.decoder_start_token_id)\nmodel.to(device)","metadata":{"id":"fzARfhH0XlT_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"20a52a51-d910-4596-fb61-e4698b9a0854","_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2022-11-05T09:58:47.424358Z","iopub.execute_input":"2022-11-05T09:58:47.424804Z","iopub.status.idle":"2022-11-05T10:00:19.509512Z","shell.execute_reply.started":"2022-11-05T09:58:47.424765Z","shell.execute_reply":"2022-11-05T10:00:19.508400Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/68.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47989924e1da4ac6acab438028fd926a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/330M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0313d85b9e754521b5abde98dbcdce07"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at google/vit-base-patch16-224 were not used when initializing ViTModel: ['classifier.bias', 'classifier.weight']\n- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/518M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61371078ac2846c6b56a49fae7bb3af3"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at aubmindlab/bert-base-arabertv2 were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertLMHeadModel were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"None\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"VisionEncoderDecoderModel(\n  (encoder): ViTModel(\n    (embeddings): ViTEmbeddings(\n      (patch_embeddings): PatchEmbeddings(\n        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n      )\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): ViTEncoder(\n      (layer): ModuleList(\n        (0): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (1): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (2): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (3): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (4): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (5): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (6): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (7): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (8): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (9): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (10): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (11): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (pooler): ViTPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (decoder): BertLMHeadModel(\n    (bert): BertModel(\n      (embeddings): BertEmbeddings(\n        (word_embeddings): Embedding(64000, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (token_type_embeddings): Embedding(2, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (encoder): BertEncoder(\n        (layer): ModuleList(\n          (0): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (crossattention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (1): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (crossattention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (2): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (crossattention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (3): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (crossattention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (4): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (crossattention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (5): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (crossattention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (6): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (crossattention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (7): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (crossattention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (8): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (crossattention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (9): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (crossattention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (10): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (crossattention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (11): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (crossattention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n    )\n    (cls): BertOnlyMLMHead(\n      (predictions): BertLMPredictionHead(\n        (transform): BertPredictionHeadTransform(\n          (dense): Linear(in_features=768, out_features=768, bias=True)\n          (transform_act_fn): GELUActivation()\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (decoder): Linear(in_features=768, out_features=64000, bias=True)\n      )\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# set special tokens used for creating the decoder_input_ids from the labels\nmodel.config.decoder_start_token_id = processor.tokenizer.cls_token_id\nmodel.config.pad_token_id = processor.tokenizer.pad_token_id\n# make sure vocab size is set correctly\nmodel.config.vocab_size = model.config.decoder.vocab_size\n\n# set beam search parameters\nmodel.config.eos_token_id = processor.tokenizer.sep_token_id\nmodel.config.max_length = 64\nmodel.config.early_stopping = True\nmodel.config.no_repeat_ngram_size = 3\nmodel.config.length_penalty = 2.0\nmodel.config.num_beams = 4","metadata":{"id":"Q7M1hB14YL_G","execution":{"iopub.status.busy":"2022-11-05T10:00:19.513745Z","iopub.execute_input":"2022-11-05T10:00:19.514152Z","iopub.status.idle":"2022-11-05T10:00:19.522222Z","shell.execute_reply.started":"2022-11-05T10:00:19.514114Z","shell.execute_reply":"2022-11-05T10:00:19.519468Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"wer_metric = load_metric(\"wer\")\n\ndef compute_wer(pred):\n    \n    labels_ids = pred.label_ids\n    pred_ids = pred.predictions\n    \n    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n\n    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n\n\n    return  {\"wer\": wer}","metadata":{"id":"rH38HwBWY6fD","execution":{"iopub.status.busy":"2022-11-05T10:00:19.523389Z","iopub.execute_input":"2022-11-05T10:00:19.523759Z","iopub.status.idle":"2022-11-05T10:00:21.458351Z","shell.execute_reply.started":"2022-11-05T10:00:19.523725Z","shell.execute_reply":"2022-11-05T10:00:21.457384Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.90k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ba2e4caebad41508817a04e17ca7357"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    predict_with_generate=True,\n    evaluation_strategy=\"steps\",\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    fp16=True, \n    output_dir=\"./\",\n    logging_steps=2,\n    save_steps=1000,\n    eval_steps=100,\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:00:21.459825Z","iopub.execute_input":"2022-11-05T10:00:21.460569Z","iopub.status.idle":"2022-11-05T10:00:22.074690Z","shell.execute_reply.started":"2022-11-05T10:00:21.460527Z","shell.execute_reply":"2022-11-05T10:00:22.073693Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from transformers import default_data_collator\n\n# instantiate trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    tokenizer=processor.tokenizer,\n    args=training_args,\n    compute_metrics=compute_wer,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    data_collator=default_data_collator,\n)\ntrainer.train()\n#trainer.save_model('./m')","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:00:22.076014Z","iopub.execute_input":"2022-11-05T10:00:22.076910Z","iopub.status.idle":"2022-11-05T10:11:08.757196Z","shell.execute_reply.started":"2022-11-05T10:00:22.076872Z","shell.execute_reply":"2022-11-05T10:11:08.756179Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Using cuda_amp half precision backend\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 1400\n  Num Epochs = 3\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 525\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20221105_100125-9w659pj0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/abr011/huggingface/runs/9w659pj0\" target=\"_blank\">./</a></strong> to <a href=\"https://wandb.ai/abr011/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [525/525 09:26, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Wer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>6.955800</td>\n      <td>6.950966</td>\n      <td>1.113402</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>6.496100</td>\n      <td>6.698384</td>\n      <td>1.556701</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>6.606200</td>\n      <td>6.776637</td>\n      <td>2.057532</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>6.441600</td>\n      <td>6.774720</td>\n      <td>1.793482</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>6.634700</td>\n      <td>6.765750</td>\n      <td>1.658131</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 233\n  Batch size = 8\n***** Running Evaluation *****\n  Num examples = 233\n  Batch size = 8\n***** Running Evaluation *****\n  Num examples = 233\n  Batch size = 8\n***** Running Evaluation *****\n  Num examples = 233\n  Batch size = 8\n***** Running Evaluation *****\n  Num examples = 233\n  Batch size = 8\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nSaving model checkpoint to ./m\nConfiguration saved in ./m/config.json\nModel weights saved in ./m/pytorch_model.bin\ntokenizer config file saved in ./m/tokenizer_config.json\nSpecial tokens file saved in ./m/special_tokens_map.json\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"import requests\nfrom io import StringIO\n#url = '../input/khattpilottest/KHATT-Pilot/Line Images/Line Images/AHTD3A0001_Para2_3.tif'\nurl='https://arabicfont.net/wp-content/uploads/2017/05/molhim-arabic-font.jpg'\nimg = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n#image = Image.open(url).convert(\"RGB\")\nimg","metadata":{"execution":{"iopub.status.busy":"2022-11-05T10:11:08.758681Z","iopub.execute_input":"2022-11-05T10:11:08.759427Z","iopub.status.idle":"2022-11-05T10:11:10.108596Z","shell.execute_reply.started":"2022-11-05T10:11:08.759387Z","shell.execute_reply":"2022-11-05T10:11:10.107552Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=608x100>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"#model = VisionEncoderDecoderModel.from_pretrained(\"./m\")\n#model= model.to(device)\np = processor(img, return_tensors=\"pt\").pixel_values\np= p.to(device)\ngenerated_ids = model.generate(p)\ngenerated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\nprint(generated_text)\nprint(generated_ids)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-11-05T10:11:10.110251Z","iopub.execute_input":"2022-11-05T10:11:10.110640Z","iopub.status.idle":"2022-11-05T10:11:19.937171Z","shell.execute_reply.started":"2022-11-05T10:11:10.110602Z","shell.execute_reply":"2022-11-05T10:11:19.936018Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"loading configuration file ./m/config.json\nModel config VisionEncoderDecoderConfig {\n  \"architectures\": [\n    \"VisionEncoderDecoderModel\"\n  ],\n  \"decoder\": {\n    \"_name_or_path\": \"aubmindlab/bert-base-arabertv2\",\n    \"add_cross_attention\": true,\n    \"architectures\": [\n      \"BertForMaskedLM\"\n    ],\n    \"attention_probs_dropout_prob\": 0.1,\n    \"bad_words_ids\": null,\n    \"bos_token_id\": null,\n    \"chunk_size_feed_forward\": 0,\n    \"classifier_dropout\": null,\n    \"cross_attention_hidden_size\": null,\n    \"decoder_start_token_id\": null,\n    \"diversity_penalty\": 0.0,\n    \"do_sample\": false,\n    \"early_stopping\": false,\n    \"encoder_no_repeat_ngram_size\": 0,\n    \"eos_token_id\": null,\n    \"exponential_decay_length_penalty\": null,\n    \"finetuning_task\": null,\n    \"forced_bos_token_id\": null,\n    \"forced_eos_token_id\": null,\n    \"hidden_act\": \"gelu\",\n    \"hidden_dropout_prob\": 0.1,\n    \"hidden_size\": 768,\n    \"id2label\": {\n      \"0\": \"LABEL_0\",\n      \"1\": \"LABEL_1\"\n    },\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 3072,\n    \"is_decoder\": true,\n    \"is_encoder_decoder\": false,\n    \"label2id\": {\n      \"LABEL_0\": 0,\n      \"LABEL_1\": 1\n    },\n    \"layer_norm_eps\": 1e-12,\n    \"length_penalty\": 1.0,\n    \"max_length\": 20,\n    \"max_position_embeddings\": 512,\n    \"min_length\": 0,\n    \"model_type\": \"bert\",\n    \"no_repeat_ngram_size\": 0,\n    \"num_attention_heads\": 12,\n    \"num_beam_groups\": 1,\n    \"num_beams\": 1,\n    \"num_hidden_layers\": 12,\n    \"num_return_sequences\": 1,\n    \"output_attentions\": false,\n    \"output_hidden_states\": false,\n    \"output_scores\": false,\n    \"pad_token_id\": 0,\n    \"position_embedding_type\": \"absolute\",\n    \"prefix\": null,\n    \"problem_type\": null,\n    \"pruned_heads\": {},\n    \"remove_invalid_values\": false,\n    \"repetition_penalty\": 1.0,\n    \"return_dict\": true,\n    \"return_dict_in_generate\": false,\n    \"sep_token_id\": null,\n    \"task_specific_params\": null,\n    \"temperature\": 1.0,\n    \"tie_encoder_decoder\": false,\n    \"tie_word_embeddings\": true,\n    \"tokenizer_class\": null,\n    \"top_k\": 50,\n    \"top_p\": 1.0,\n    \"torch_dtype\": null,\n    \"torchscript\": false,\n    \"transformers_version\": \"4.20.1\",\n    \"type_vocab_size\": 2,\n    \"typical_p\": 1.0,\n    \"use_bfloat16\": false,\n    \"use_cache\": true,\n    \"vocab_size\": 64000\n  },\n  \"decoder_start_token_id\": 33,\n  \"early_stopping\": true,\n  \"encoder\": {\n    \"_name_or_path\": \"google/vit-base-patch16-224\",\n    \"add_cross_attention\": false,\n    \"architectures\": [\n      \"ViTForImageClassification\"\n    ],\n    \"attention_probs_dropout_prob\": 0.0,\n    \"bad_words_ids\": null,\n    \"bos_token_id\": null,\n    \"chunk_size_feed_forward\": 0,\n    \"cross_attention_hidden_size\": null,\n    \"decoder_start_token_id\": null,\n    \"diversity_penalty\": 0.0,\n    \"do_sample\": false,\n    \"early_stopping\": false,\n    \"encoder_no_repeat_ngram_size\": 0,\n    \"encoder_stride\": 16,\n    \"eos_token_id\": null,\n    \"exponential_decay_length_penalty\": null,\n    \"finetuning_task\": null,\n    \"forced_bos_token_id\": null,\n    \"forced_eos_token_id\": null,\n    \"hidden_act\": \"gelu\",\n    \"hidden_dropout_prob\": 0.0,\n    \"hidden_size\": 768,\n    \"id2label\": {\n      \"0\": \"tench, Tinca tinca\",\n      \"1\": \"goldfish, Carassius auratus\",\n      \"2\": \"great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias\",\n      \"3\": \"tiger shark, Galeocerdo cuvieri\",\n      \"4\": \"hammerhead, hammerhead shark\",\n      \"5\": \"electric ray, crampfish, numbfish, torpedo\",\n      \"6\": \"stingray\",\n      \"7\": \"cock\",\n      \"8\": \"hen\",\n      \"9\": \"ostrich, Struthio camelus\",\n      \"10\": \"brambling, Fringilla montifringilla\",\n      \"11\": \"goldfinch, Carduelis carduelis\",\n      \"12\": \"house finch, linnet, Carpodacus mexicanus\",\n      \"13\": \"junco, snowbird\",\n      \"14\": \"indigo bunting, indigo finch, indigo bird, Passerina cyanea\",\n      \"15\": \"robin, American robin, Turdus migratorius\",\n      \"16\": \"bulbul\",\n      \"17\": \"jay\",\n      \"18\": \"magpie\",\n      \"19\": \"chickadee\",\n      \"20\": \"water ouzel, dipper\",\n      \"21\": \"kite\",\n      \"22\": \"bald eagle, American eagle, Haliaeetus leucocephalus\",\n      \"23\": \"vulture\",\n      \"24\": \"great grey owl, great gray owl, Strix nebulosa\",\n      \"25\": \"European fire salamander, Salamandra salamandra\",\n      \"26\": \"common newt, Triturus vulgaris\",\n      \"27\": \"eft\",\n      \"28\": \"spotted salamander, Ambystoma maculatum\",\n      \"29\": \"axolotl, mud puppy, Ambystoma mexicanum\",\n      \"30\": \"bullfrog, Rana catesbeiana\",\n      \"31\": \"tree frog, tree-frog\",\n      \"32\": \"tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui\",\n      \"33\": \"loggerhead, loggerhead turtle, Caretta caretta\",\n      \"34\": \"leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea\",\n      \"35\": \"mud turtle\",\n      \"36\": \"terrapin\",\n      \"37\": \"box turtle, box tortoise\",\n      \"38\": \"banded gecko\",\n      \"39\": \"common iguana, iguana, Iguana iguana\",\n      \"40\": \"American chameleon, anole, Anolis carolinensis\",\n      \"41\": \"whiptail, whiptail lizard\",\n      \"42\": \"agama\",\n      \"43\": \"frilled lizard, Chlamydosaurus kingi\",\n      \"44\": \"alligator lizard\",\n      \"45\": \"Gila monster, Heloderma suspectum\",\n      \"46\": \"green lizard, Lacerta viridis\",\n      \"47\": \"African chameleon, Chamaeleo chamaeleon\",\n      \"48\": \"Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis\",\n      \"49\": \"African crocodile, Nile crocodile, Crocodylus niloticus\",\n      \"50\": \"American alligator, Alligator mississipiensis\",\n      \"51\": \"triceratops\",\n      \"52\": \"thunder snake, worm snake, Carphophis amoenus\",\n      \"53\": \"ringneck snake, ring-necked snake, ring snake\",\n      \"54\": \"hognose snake, puff adder, sand viper\",\n      \"55\": \"green snake, grass snake\",\n      \"56\": \"king snake, kingsnake\",\n      \"57\": \"garter snake, grass snake\",\n      \"58\": \"water snake\",\n      \"59\": \"vine snake\",\n      \"60\": \"night snake, Hypsiglena torquata\",\n      \"61\": \"boa constrictor, Constrictor constrictor\",\n      \"62\": \"rock python, rock snake, Python sebae\",\n      \"63\": \"Indian cobra, Naja naja\",\n      \"64\": \"green mamba\",\n      \"65\": \"sea snake\",\n      \"66\": \"horned viper, cerastes, sand viper, horned asp, Cerastes cornutus\",\n      \"67\": \"diamondback, diamondback rattlesnake, Crotalus adamanteus\",\n      \"68\": \"sidewinder, horned rattlesnake, Crotalus cerastes\",\n      \"69\": \"trilobite\",\n      \"70\": \"harvestman, daddy longlegs, Phalangium opilio\",\n      \"71\": \"scorpion\",\n      \"72\": \"black and gold garden spider, Argiope aurantia\",\n      \"73\": \"barn spider, Araneus cavaticus\",\n      \"74\": \"garden spider, Aranea diademata\",\n      \"75\": \"black widow, Latrodectus mactans\",\n      \"76\": \"tarantula\",\n      \"77\": \"wolf spider, hunting spider\",\n      \"78\": \"tick\",\n      \"79\": \"centipede\",\n      \"80\": \"black grouse\",\n      \"81\": \"ptarmigan\",\n      \"82\": \"ruffed grouse, partridge, Bonasa umbellus\",\n      \"83\": \"prairie chicken, prairie grouse, prairie fowl\",\n      \"84\": \"peacock\",\n      \"85\": \"quail\",\n      \"86\": \"partridge\",\n      \"87\": \"African grey, African gray, Psittacus erithacus\",\n      \"88\": \"macaw\",\n      \"89\": \"sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita\",\n      \"90\": \"lorikeet\",\n      \"91\": \"coucal\",\n      \"92\": \"bee eater\",\n      \"93\": \"hornbill\",\n      \"94\": \"hummingbird\",\n      \"95\": \"jacamar\",\n      \"96\": \"toucan\",\n      \"97\": \"drake\",\n      \"98\": \"red-breasted merganser, Mergus serrator\",\n      \"99\": \"goose\",\n      \"100\": \"black swan, Cygnus atratus\",\n      \"101\": \"tusker\",\n      \"102\": \"echidna, spiny anteater, anteater\",\n      \"103\": \"platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus\",\n      \"104\": \"wallaby, brush kangaroo\",\n      \"105\": \"koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus\",\n      \"106\": \"wombat\",\n      \"107\": \"jellyfish\",\n      \"108\": \"sea anemone, anemone\",\n      \"109\": \"brain coral\",\n      \"110\": \"flatworm, platyhelminth\",\n      \"111\": \"nematode, nematode worm, roundworm\",\n      \"112\": \"conch\",\n      \"113\": \"snail\",\n      \"114\": \"slug\",\n      \"115\": \"sea slug, nudibranch\",\n      \"116\": \"chiton, coat-of-mail shell, sea cradle, polyplacophore\",\n      \"117\": \"chambered nautilus, pearly nautilus, nautilus\",\n      \"118\": \"Dungeness crab, Cancer magister\",\n      \"119\": \"rock crab, Cancer irroratus\",\n      \"120\": \"fiddler crab\",\n      \"121\": \"king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodes camtschatica\",\n      \"122\": \"American lobster, Northern lobster, Maine lobster, Homarus americanus\",\n      \"123\": \"spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish\",\n      \"124\": \"crayfish, crawfish, crawdad, crawdaddy\",\n      \"125\": \"hermit crab\",\n      \"126\": \"isopod\",\n      \"127\": \"white stork, Ciconia ciconia\",\n      \"128\": \"black stork, Ciconia nigra\",\n      \"129\": \"spoonbill\",\n      \"130\": \"flamingo\",\n      \"131\": \"little blue heron, Egretta caerulea\",\n      \"132\": \"American egret, great white heron, Egretta albus\",\n      \"133\": \"bittern\",\n      \"134\": \"crane\",\n      \"135\": \"limpkin, Aramus pictus\",\n      \"136\": \"European gallinule, Porphyrio porphyrio\",\n      \"137\": \"American coot, marsh hen, mud hen, water hen, Fulica americana\",\n      \"138\": \"bustard\",\n      \"139\": \"ruddy turnstone, Arenaria interpres\",\n      \"140\": \"red-backed sandpiper, dunlin, Erolia alpina\",\n      \"141\": \"redshank, Tringa totanus\",\n      \"142\": \"dowitcher\",\n      \"143\": \"oystercatcher, oyster catcher\",\n      \"144\": \"pelican\",\n      \"145\": \"king penguin, Aptenodytes patagonica\",\n      \"146\": \"albatross, mollymawk\",\n      \"147\": \"grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus\",\n      \"148\": \"killer whale, killer, orca, grampus, sea wolf, Orcinus orca\",\n      \"149\": \"dugong, Dugong dugon\",\n      \"150\": \"sea lion\",\n      \"151\": \"Chihuahua\",\n      \"152\": \"Japanese spaniel\",\n      \"153\": \"Maltese dog, Maltese terrier, Maltese\",\n      \"154\": \"Pekinese, Pekingese, Peke\",\n      \"155\": \"Shih-Tzu\",\n      \"156\": \"Blenheim spaniel\",\n      \"157\": \"papillon\",\n      \"158\": \"toy terrier\",\n      \"159\": \"Rhodesian ridgeback\",\n      \"160\": \"Afghan hound, Afghan\",\n      \"161\": \"basset, basset hound\",\n      \"162\": \"beagle\",\n      \"163\": \"bloodhound, sleuthhound\",\n      \"164\": \"bluetick\",\n      \"165\": \"black-and-tan coonhound\",\n      \"166\": \"Walker hound, Walker foxhound\",\n      \"167\": \"English foxhound\",\n      \"168\": \"redbone\",\n      \"169\": \"borzoi, Russian wolfhound\",\n      \"170\": \"Irish wolfhound\",\n      \"171\": \"Italian greyhound\",\n      \"172\": \"whippet\",\n      \"173\": \"Ibizan hound, Ibizan Podenco\",\n      \"174\": \"Norwegian elkhound, elkhound\",\n      \"175\": \"otterhound, otter hound\",\n      \"176\": \"Saluki, gazelle hound\",\n      \"177\": \"Scottish deerhound, deerhound\",\n      \"178\": \"Weimaraner\",\n      \"179\": \"Staffordshire bullterrier, Staffordshire bull terrier\",\n      \"180\": \"American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier\",\n      \"181\": \"Bedlington terrier\",\n      \"182\": \"Border terrier\",\n      \"183\": \"Kerry blue terrier\",\n      \"184\": \"Irish terrier\",\n      \"185\": \"Norfolk terrier\",\n      \"186\": \"Norwich terrier\",\n      \"187\": \"Yorkshire terrier\",\n      \"188\": \"wire-haired fox terrier\",\n      \"189\": \"Lakeland terrier\",\n      \"190\": \"Sealyham terrier, Sealyham\",\n      \"191\": \"Airedale, Airedale terrier\",\n      \"192\": \"cairn, cairn terrier\",\n      \"193\": \"Australian terrier\",\n      \"194\": \"Dandie Dinmont, Dandie Dinmont terrier\",\n      \"195\": \"Boston bull, Boston terrier\",\n      \"196\": \"miniature schnauzer\",\n      \"197\": \"giant schnauzer\",\n      \"198\": \"standard schnauzer\",\n      \"199\": \"Scotch terrier, Scottish terrier, Scottie\",\n      \"200\": \"Tibetan terrier, chrysanthemum dog\",\n      \"201\": \"silky terrier, Sydney silky\",\n      \"202\": \"soft-coated wheaten terrier\",\n      \"203\": \"West Highland white terrier\",\n      \"204\": \"Lhasa, Lhasa apso\",\n      \"205\": \"flat-coated retriever\",\n      \"206\": \"curly-coated retriever\",\n      \"207\": \"golden retriever\",\n      \"208\": \"Labrador retriever\",\n      \"209\": \"Chesapeake Bay retriever\",\n      \"210\": \"German short-haired pointer\",\n      \"211\": \"vizsla, Hungarian pointer\",\n      \"212\": \"English setter\",\n      \"213\": \"Irish setter, red setter\",\n      \"214\": \"Gordon setter\",\n      \"215\": \"Brittany spaniel\",\n      \"216\": \"clumber, clumber spaniel\",\n      \"217\": \"English springer, English springer spaniel\",\n      \"218\": \"Welsh springer spaniel\",\n      \"219\": \"cocker spaniel, English cocker spaniel, cocker\",\n      \"220\": \"Sussex spaniel\",\n      \"221\": \"Irish water spaniel\",\n      \"222\": \"kuvasz\",\n      \"223\": \"schipperke\",\n      \"224\": \"groenendael\",\n      \"225\": \"malinois\",\n      \"226\": \"briard\",\n      \"227\": \"kelpie\",\n      \"228\": \"komondor\",\n      \"229\": \"Old English sheepdog, bobtail\",\n      \"230\": \"Shetland sheepdog, Shetland sheep dog, Shetland\",\n      \"231\": \"collie\",\n      \"232\": \"Border collie\",\n      \"233\": \"Bouvier des Flandres, Bouviers des Flandres\",\n      \"234\": \"Rottweiler\",\n      \"235\": \"German shepherd, German shepherd dog, German police dog, alsatian\",\n      \"236\": \"Doberman, Doberman pinscher\",\n      \"237\": \"miniature pinscher\",\n      \"238\": \"Greater Swiss Mountain dog\",\n      \"239\": \"Bernese mountain dog\",\n      \"240\": \"Appenzeller\",\n      \"241\": \"EntleBucher\",\n      \"242\": \"boxer\",\n      \"243\": \"bull mastiff\",\n      \"244\": \"Tibetan mastiff\",\n      \"245\": \"French bulldog\",\n      \"246\": \"Great Dane\",\n      \"247\": \"Saint Bernard, St Bernard\",\n      \"248\": \"Eskimo dog, husky\",\n      \"249\": \"malamute, malemute, Alaskan malamute\",\n      \"250\": \"Siberian husky\",\n      \"251\": \"dalmatian, coach dog, carriage dog\",\n      \"252\": \"affenpinscher, monkey pinscher, monkey dog\",\n      \"253\": \"basenji\",\n      \"254\": \"pug, pug-dog\",\n      \"255\": \"Leonberg\",\n      \"256\": \"Newfoundland, Newfoundland dog\",\n      \"257\": \"Great Pyrenees\",\n      \"258\": \"Samoyed, Samoyede\",\n      \"259\": \"Pomeranian\",\n      \"260\": \"chow, chow chow\",\n      \"261\": \"keeshond\",\n      \"262\": \"Brabancon griffon\",\n      \"263\": \"Pembroke, Pembroke Welsh corgi\",\n      \"264\": \"Cardigan, Cardigan Welsh corgi\",\n      \"265\": \"toy poodle\",\n      \"266\": \"miniature poodle\",\n      \"267\": \"standard poodle\",\n      \"268\": \"Mexican hairless\",\n      \"269\": \"timber wolf, grey wolf, gray wolf, Canis lupus\",\n      \"270\": \"white wolf, Arctic wolf, Canis lupus tundrarum\",\n      \"271\": \"red wolf, maned wolf, Canis rufus, Canis niger\",\n      \"272\": \"coyote, prairie wolf, brush wolf, Canis latrans\",\n      \"273\": \"dingo, warrigal, warragal, Canis dingo\",\n      \"274\": \"dhole, Cuon alpinus\",\n      \"275\": \"African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus\",\n      \"276\": \"hyena, hyaena\",\n      \"277\": \"red fox, Vulpes vulpes\",\n      \"278\": \"kit fox, Vulpes macrotis\",\n      \"279\": \"Arctic fox, white fox, Alopex lagopus\",\n      \"280\": \"grey fox, gray fox, Urocyon cinereoargenteus\",\n      \"281\": \"tabby, tabby cat\",\n      \"282\": \"tiger cat\",\n      \"283\": \"Persian cat\",\n      \"284\": \"Siamese cat, Siamese\",\n      \"285\": \"Egyptian cat\",\n      \"286\": \"cougar, puma, catamount, mountain lion, painter, panther, Felis concolor\",\n      \"287\": \"lynx, catamount\",\n      \"288\": \"leopard, Panthera pardus\",\n      \"289\": \"snow leopard, ounce, Panthera uncia\",\n      \"290\": \"jaguar, panther, Panthera onca, Felis onca\",\n      \"291\": \"lion, king of beasts, Panthera leo\",\n      \"292\": \"tiger, Panthera tigris\",\n      \"293\": \"cheetah, chetah, Acinonyx jubatus\",\n      \"294\": \"brown bear, bruin, Ursus arctos\",\n      \"295\": \"American black bear, black bear, Ursus americanus, Euarctos americanus\",\n      \"296\": \"ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus\",\n      \"297\": \"sloth bear, Melursus ursinus, Ursus ursinus\",\n      \"298\": \"mongoose\",\n      \"299\": \"meerkat, mierkat\",\n      \"300\": \"tiger beetle\",\n      \"301\": \"ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle\",\n      \"302\": \"ground beetle, carabid beetle\",\n      \"303\": \"long-horned beetle, longicorn, longicorn beetle\",\n      \"304\": \"leaf beetle, chrysomelid\",\n      \"305\": \"dung beetle\",\n      \"306\": \"rhinoceros beetle\",\n      \"307\": \"weevil\",\n      \"308\": \"fly\",\n      \"309\": \"bee\",\n      \"310\": \"ant, emmet, pismire\",\n      \"311\": \"grasshopper, hopper\",\n      \"312\": \"cricket\",\n      \"313\": \"walking stick, walkingstick, stick insect\",\n      \"314\": \"cockroach, roach\",\n      \"315\": \"mantis, mantid\",\n      \"316\": \"cicada, cicala\",\n      \"317\": \"leafhopper\",\n      \"318\": \"lacewing, lacewing fly\",\n      \"319\": \"dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk\",\n      \"320\": \"damselfly\",\n      \"321\": \"admiral\",\n      \"322\": \"ringlet, ringlet butterfly\",\n      \"323\": \"monarch, monarch butterfly, milkweed butterfly, Danaus plexippus\",\n      \"324\": \"cabbage butterfly\",\n      \"325\": \"sulphur butterfly, sulfur butterfly\",\n      \"326\": \"lycaenid, lycaenid butterfly\",\n      \"327\": \"starfish, sea star\",\n      \"328\": \"sea urchin\",\n      \"329\": \"sea cucumber, holothurian\",\n      \"330\": \"wood rabbit, cottontail, cottontail rabbit\",\n      \"331\": \"hare\",\n      \"332\": \"Angora, Angora rabbit\",\n      \"333\": \"hamster\",\n      \"334\": \"porcupine, hedgehog\",\n      \"335\": \"fox squirrel, eastern fox squirrel, Sciurus niger\",\n      \"336\": \"marmot\",\n      \"337\": \"beaver\",\n      \"338\": \"guinea pig, Cavia cobaya\",\n      \"339\": \"sorrel\",\n      \"340\": \"zebra\",\n      \"341\": \"hog, pig, grunter, squealer, Sus scrofa\",\n      \"342\": \"wild boar, boar, Sus scrofa\",\n      \"343\": \"warthog\",\n      \"344\": \"hippopotamus, hippo, river horse, Hippopotamus amphibius\",\n      \"345\": \"ox\",\n      \"346\": \"water buffalo, water ox, Asiatic buffalo, Bubalus bubalis\",\n      \"347\": \"bison\",\n      \"348\": \"ram, tup\",\n      \"349\": \"bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis\",\n      \"350\": \"ibex, Capra ibex\",\n      \"351\": \"hartebeest\",\n      \"352\": \"impala, Aepyceros melampus\",\n      \"353\": \"gazelle\",\n      \"354\": \"Arabian camel, dromedary, Camelus dromedarius\",\n      \"355\": \"llama\",\n      \"356\": \"weasel\",\n      \"357\": \"mink\",\n      \"358\": \"polecat, fitch, foulmart, foumart, Mustela putorius\",\n      \"359\": \"black-footed ferret, ferret, Mustela nigripes\",\n      \"360\": \"otter\",\n      \"361\": \"skunk, polecat, wood pussy\",\n      \"362\": \"badger\",\n      \"363\": \"armadillo\",\n      \"364\": \"three-toed sloth, ai, Bradypus tridactylus\",\n      \"365\": \"orangutan, orang, orangutang, Pongo pygmaeus\",\n      \"366\": \"gorilla, Gorilla gorilla\",\n      \"367\": \"chimpanzee, chimp, Pan troglodytes\",\n      \"368\": \"gibbon, Hylobates lar\",\n      \"369\": \"siamang, Hylobates syndactylus, Symphalangus syndactylus\",\n      \"370\": \"guenon, guenon monkey\",\n      \"371\": \"patas, hussar monkey, Erythrocebus patas\",\n      \"372\": \"baboon\",\n      \"373\": \"macaque\",\n      \"374\": \"langur\",\n      \"375\": \"colobus, colobus monkey\",\n      \"376\": \"proboscis monkey, Nasalis larvatus\",\n      \"377\": \"marmoset\",\n      \"378\": \"capuchin, ringtail, Cebus capucinus\",\n      \"379\": \"howler monkey, howler\",\n      \"380\": \"titi, titi monkey\",\n      \"381\": \"spider monkey, Ateles geoffroyi\",\n      \"382\": \"squirrel monkey, Saimiri sciureus\",\n      \"383\": \"Madagascar cat, ring-tailed lemur, Lemur catta\",\n      \"384\": \"indri, indris, Indri indri, Indri brevicaudatus\",\n      \"385\": \"Indian elephant, Elephas maximus\",\n      \"386\": \"African elephant, Loxodonta africana\",\n      \"387\": \"lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens\",\n      \"388\": \"giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca\",\n      \"389\": \"barracouta, snoek\",\n      \"390\": \"eel\",\n      \"391\": \"coho, cohoe, coho salmon, blue jack, silver salmon, Oncorhynchus kisutch\",\n      \"392\": \"rock beauty, Holocanthus tricolor\",\n      \"393\": \"anemone fish\",\n      \"394\": \"sturgeon\",\n      \"395\": \"gar, garfish, garpike, billfish, Lepisosteus osseus\",\n      \"396\": \"lionfish\",\n      \"397\": \"puffer, pufferfish, blowfish, globefish\",\n      \"398\": \"abacus\",\n      \"399\": \"abaya\",\n      \"400\": \"academic gown, academic robe, judge's robe\",\n      \"401\": \"accordion, piano accordion, squeeze box\",\n      \"402\": \"acoustic guitar\",\n      \"403\": \"aircraft carrier, carrier, flattop, attack aircraft carrier\",\n      \"404\": \"airliner\",\n      \"405\": \"airship, dirigible\",\n      \"406\": \"altar\",\n      \"407\": \"ambulance\",\n      \"408\": \"amphibian, amphibious vehicle\",\n      \"409\": \"analog clock\",\n      \"410\": \"apiary, bee house\",\n      \"411\": \"apron\",\n      \"412\": \"ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin\",\n      \"413\": \"assault rifle, assault gun\",\n      \"414\": \"backpack, back pack, knapsack, packsack, rucksack, haversack\",\n      \"415\": \"bakery, bakeshop, bakehouse\",\n      \"416\": \"balance beam, beam\",\n      \"417\": \"balloon\",\n      \"418\": \"ballpoint, ballpoint pen, ballpen, Biro\",\n      \"419\": \"Band Aid\",\n      \"420\": \"banjo\",\n      \"421\": \"bannister, banister, balustrade, balusters, handrail\",\n      \"422\": \"barbell\",\n      \"423\": \"barber chair\",\n      \"424\": \"barbershop\",\n      \"425\": \"barn\",\n      \"426\": \"barometer\",\n      \"427\": \"barrel, cask\",\n      \"428\": \"barrow, garden cart, lawn cart, wheelbarrow\",\n      \"429\": \"baseball\",\n      \"430\": \"basketball\",\n      \"431\": \"bassinet\",\n      \"432\": \"bassoon\",\n      \"433\": \"bathing cap, swimming cap\",\n      \"434\": \"bath towel\",\n      \"435\": \"bathtub, bathing tub, bath, tub\",\n      \"436\": \"beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon\",\n      \"437\": \"beacon, lighthouse, beacon light, pharos\",\n      \"438\": \"beaker\",\n      \"439\": \"bearskin, busby, shako\",\n      \"440\": \"beer bottle\",\n      \"441\": \"beer glass\",\n      \"442\": \"bell cote, bell cot\",\n      \"443\": \"bib\",\n      \"444\": \"bicycle-built-for-two, tandem bicycle, tandem\",\n      \"445\": \"bikini, two-piece\",\n      \"446\": \"binder, ring-binder\",\n      \"447\": \"binoculars, field glasses, opera glasses\",\n      \"448\": \"birdhouse\",\n      \"449\": \"boathouse\",\n      \"450\": \"bobsled, bobsleigh, bob\",\n      \"451\": \"bolo tie, bolo, bola tie, bola\",\n      \"452\": \"bonnet, poke bonnet\",\n      \"453\": \"bookcase\",\n      \"454\": \"bookshop, bookstore, bookstall\",\n      \"455\": \"bottlecap\",\n      \"456\": \"bow\",\n      \"457\": \"bow tie, bow-tie, bowtie\",\n      \"458\": \"brass, memorial tablet, plaque\",\n      \"459\": \"brassiere, bra, bandeau\",\n      \"460\": \"breakwater, groin, groyne, mole, bulwark, seawall, jetty\",\n      \"461\": \"breastplate, aegis, egis\",\n      \"462\": \"broom\",\n      \"463\": \"bucket, pail\",\n      \"464\": \"buckle\",\n      \"465\": \"bulletproof vest\",\n      \"466\": \"bullet train, bullet\",\n      \"467\": \"butcher shop, meat market\",\n      \"468\": \"cab, hack, taxi, taxicab\",\n      \"469\": \"caldron, cauldron\",\n      \"470\": \"candle, taper, wax light\",\n      \"471\": \"cannon\",\n      \"472\": \"canoe\",\n      \"473\": \"can opener, tin opener\",\n      \"474\": \"cardigan\",\n      \"475\": \"car mirror\",\n      \"476\": \"carousel, carrousel, merry-go-round, roundabout, whirligig\",\n      \"477\": \"carpenter's kit, tool kit\",\n      \"478\": \"carton\",\n      \"479\": \"car wheel\",\n      \"480\": \"cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM\",\n      \"481\": \"cassette\",\n      \"482\": \"cassette player\",\n      \"483\": \"castle\",\n      \"484\": \"catamaran\",\n      \"485\": \"CD player\",\n      \"486\": \"cello, violoncello\",\n      \"487\": \"cellular telephone, cellular phone, cellphone, cell, mobile phone\",\n      \"488\": \"chain\",\n      \"489\": \"chainlink fence\",\n      \"490\": \"chain mail, ring mail, mail, chain armor, chain armour, ring armor, ring armour\",\n      \"491\": \"chain saw, chainsaw\",\n      \"492\": \"chest\",\n      \"493\": \"chiffonier, commode\",\n      \"494\": \"chime, bell, gong\",\n      \"495\": \"china cabinet, china closet\",\n      \"496\": \"Christmas stocking\",\n      \"497\": \"church, church building\",\n      \"498\": \"cinema, movie theater, movie theatre, movie house, picture palace\",\n      \"499\": \"cleaver, meat cleaver, chopper\",\n      \"500\": \"cliff dwelling\",\n      \"501\": \"cloak\",\n      \"502\": \"clog, geta, patten, sabot\",\n      \"503\": \"cocktail shaker\",\n      \"504\": \"coffee mug\",\n      \"505\": \"coffeepot\",\n      \"506\": \"coil, spiral, volute, whorl, helix\",\n      \"507\": \"combination lock\",\n      \"508\": \"computer keyboard, keypad\",\n      \"509\": \"confectionery, confectionary, candy store\",\n      \"510\": \"container ship, containership, container vessel\",\n      \"511\": \"convertible\",\n      \"512\": \"corkscrew, bottle screw\",\n      \"513\": \"cornet, horn, trumpet, trump\",\n      \"514\": \"cowboy boot\",\n      \"515\": \"cowboy hat, ten-gallon hat\",\n      \"516\": \"cradle\",\n      \"517\": \"crane\",\n      \"518\": \"crash helmet\",\n      \"519\": \"crate\",\n      \"520\": \"crib, cot\",\n      \"521\": \"Crock Pot\",\n      \"522\": \"croquet ball\",\n      \"523\": \"crutch\",\n      \"524\": \"cuirass\",\n      \"525\": \"dam, dike, dyke\",\n      \"526\": \"desk\",\n      \"527\": \"desktop computer\",\n      \"528\": \"dial telephone, dial phone\",\n      \"529\": \"diaper, nappy, napkin\",\n      \"530\": \"digital clock\",\n      \"531\": \"digital watch\",\n      \"532\": \"dining table, board\",\n      \"533\": \"dishrag, dishcloth\",\n      \"534\": \"dishwasher, dish washer, dishwashing machine\",\n      \"535\": \"disk brake, disc brake\",\n      \"536\": \"dock, dockage, docking facility\",\n      \"537\": \"dogsled, dog sled, dog sleigh\",\n      \"538\": \"dome\",\n      \"539\": \"doormat, welcome mat\",\n      \"540\": \"drilling platform, offshore rig\",\n      \"541\": \"drum, membranophone, tympan\",\n      \"542\": \"drumstick\",\n      \"543\": \"dumbbell\",\n      \"544\": \"Dutch oven\",\n      \"545\": \"electric fan, blower\",\n      \"546\": \"electric guitar\",\n      \"547\": \"electric locomotive\",\n      \"548\": \"entertainment center\",\n      \"549\": \"envelope\",\n      \"550\": \"espresso maker\",\n      \"551\": \"face powder\",\n      \"552\": \"feather boa, boa\",\n      \"553\": \"file, file cabinet, filing cabinet\",\n      \"554\": \"fireboat\",\n      \"555\": \"fire engine, fire truck\",\n      \"556\": \"fire screen, fireguard\",\n      \"557\": \"flagpole, flagstaff\",\n      \"558\": \"flute, transverse flute\",\n      \"559\": \"folding chair\",\n      \"560\": \"football helmet\",\n      \"561\": \"forklift\",\n      \"562\": \"fountain\",\n      \"563\": \"fountain pen\",\n      \"564\": \"four-poster\",\n      \"565\": \"freight car\",\n      \"566\": \"French horn, horn\",\n      \"567\": \"frying pan, frypan, skillet\",\n      \"568\": \"fur coat\",\n      \"569\": \"garbage truck, dustcart\",\n      \"570\": \"gasmask, respirator, gas helmet\",\n      \"571\": \"gas pump, gasoline pump, petrol pump, island dispenser\",\n      \"572\": \"goblet\",\n      \"573\": \"go-kart\",\n      \"574\": \"golf ball\",\n      \"575\": \"golfcart, golf cart\",\n      \"576\": \"gondola\",\n      \"577\": \"gong, tam-tam\",\n      \"578\": \"gown\",\n      \"579\": \"grand piano, grand\",\n      \"580\": \"greenhouse, nursery, glasshouse\",\n      \"581\": \"grille, radiator grille\",\n      \"582\": \"grocery store, grocery, food market, market\",\n      \"583\": \"guillotine\",\n      \"584\": \"hair slide\",\n      \"585\": \"hair spray\",\n      \"586\": \"half track\",\n      \"587\": \"hammer\",\n      \"588\": \"hamper\",\n      \"589\": \"hand blower, blow dryer, blow drier, hair dryer, hair drier\",\n      \"590\": \"hand-held computer, hand-held microcomputer\",\n      \"591\": \"handkerchief, hankie, hanky, hankey\",\n      \"592\": \"hard disc, hard disk, fixed disk\",\n      \"593\": \"harmonica, mouth organ, harp, mouth harp\",\n      \"594\": \"harp\",\n      \"595\": \"harvester, reaper\",\n      \"596\": \"hatchet\",\n      \"597\": \"holster\",\n      \"598\": \"home theater, home theatre\",\n      \"599\": \"honeycomb\",\n      \"600\": \"hook, claw\",\n      \"601\": \"hoopskirt, crinoline\",\n      \"602\": \"horizontal bar, high bar\",\n      \"603\": \"horse cart, horse-cart\",\n      \"604\": \"hourglass\",\n      \"605\": \"iPod\",\n      \"606\": \"iron, smoothing iron\",\n      \"607\": \"jack-o'-lantern\",\n      \"608\": \"jean, blue jean, denim\",\n      \"609\": \"jeep, landrover\",\n      \"610\": \"jersey, T-shirt, tee shirt\",\n      \"611\": \"jigsaw puzzle\",\n      \"612\": \"jinrikisha, ricksha, rickshaw\",\n      \"613\": \"joystick\",\n      \"614\": \"kimono\",\n      \"615\": \"knee pad\",\n      \"616\": \"knot\",\n      \"617\": \"lab coat, laboratory coat\",\n      \"618\": \"ladle\",\n      \"619\": \"lampshade, lamp shade\",\n      \"620\": \"laptop, laptop computer\",\n      \"621\": \"lawn mower, mower\",\n      \"622\": \"lens cap, lens cover\",\n      \"623\": \"letter opener, paper knife, paperknife\",\n      \"624\": \"library\",\n      \"625\": \"lifeboat\",\n      \"626\": \"lighter, light, igniter, ignitor\",\n      \"627\": \"limousine, limo\",\n      \"628\": \"liner, ocean liner\",\n      \"629\": \"lipstick, lip rouge\",\n      \"630\": \"Loafer\",\n      \"631\": \"lotion\",\n      \"632\": \"loudspeaker, speaker, speaker unit, loudspeaker system, speaker system\",\n      \"633\": \"loupe, jeweler's loupe\",\n      \"634\": \"lumbermill, sawmill\",\n      \"635\": \"magnetic compass\",\n      \"636\": \"mailbag, postbag\",\n      \"637\": \"mailbox, letter box\",\n      \"638\": \"maillot\",\n      \"639\": \"maillot, tank suit\",\n      \"640\": \"manhole cover\",\n      \"641\": \"maraca\",\n      \"642\": \"marimba, xylophone\",\n      \"643\": \"mask\",\n      \"644\": \"matchstick\",\n      \"645\": \"maypole\",\n      \"646\": \"maze, labyrinth\",\n      \"647\": \"measuring cup\",\n      \"648\": \"medicine chest, medicine cabinet\",\n      \"649\": \"megalith, megalithic structure\",\n      \"650\": \"microphone, mike\",\n      \"651\": \"microwave, microwave oven\",\n      \"652\": \"military uniform\",\n      \"653\": \"milk can\",\n      \"654\": \"minibus\",\n      \"655\": \"miniskirt, mini\",\n      \"656\": \"minivan\",\n      \"657\": \"missile\",\n      \"658\": \"mitten\",\n      \"659\": \"mixing bowl\",\n      \"660\": \"mobile home, manufactured home\",\n      \"661\": \"Model T\",\n      \"662\": \"modem\",\n      \"663\": \"monastery\",\n      \"664\": \"monitor\",\n      \"665\": \"moped\",\n      \"666\": \"mortar\",\n      \"667\": \"mortarboard\",\n      \"668\": \"mosque\",\n      \"669\": \"mosquito net\",\n      \"670\": \"motor scooter, scooter\",\n      \"671\": \"mountain bike, all-terrain bike, off-roader\",\n      \"672\": \"mountain tent\",\n      \"673\": \"mouse, computer mouse\",\n      \"674\": \"mousetrap\",\n      \"675\": \"moving van\",\n      \"676\": \"muzzle\",\n      \"677\": \"nail\",\n      \"678\": \"neck brace\",\n      \"679\": \"necklace\",\n      \"680\": \"nipple\",\n      \"681\": \"notebook, notebook computer\",\n      \"682\": \"obelisk\",\n      \"683\": \"oboe, hautboy, hautbois\",\n      \"684\": \"ocarina, sweet potato\",\n      \"685\": \"odometer, hodometer, mileometer, milometer\",\n      \"686\": \"oil filter\",\n      \"687\": \"organ, pipe organ\",\n      \"688\": \"oscilloscope, scope, cathode-ray oscilloscope, CRO\",\n      \"689\": \"overskirt\",\n      \"690\": \"oxcart\",\n      \"691\": \"oxygen mask\",\n      \"692\": \"packet\",\n      \"693\": \"paddle, boat paddle\",\n      \"694\": \"paddlewheel, paddle wheel\",\n      \"695\": \"padlock\",\n      \"696\": \"paintbrush\",\n      \"697\": \"pajama, pyjama, pj's, jammies\",\n      \"698\": \"palace\",\n      \"699\": \"panpipe, pandean pipe, syrinx\",\n      \"700\": \"paper towel\",\n      \"701\": \"parachute, chute\",\n      \"702\": \"parallel bars, bars\",\n      \"703\": \"park bench\",\n      \"704\": \"parking meter\",\n      \"705\": \"passenger car, coach, carriage\",\n      \"706\": \"patio, terrace\",\n      \"707\": \"pay-phone, pay-station\",\n      \"708\": \"pedestal, plinth, footstall\",\n      \"709\": \"pencil box, pencil case\",\n      \"710\": \"pencil sharpener\",\n      \"711\": \"perfume, essence\",\n      \"712\": \"Petri dish\",\n      \"713\": \"photocopier\",\n      \"714\": \"pick, plectrum, plectron\",\n      \"715\": \"pickelhaube\",\n      \"716\": \"picket fence, paling\",\n      \"717\": \"pickup, pickup truck\",\n      \"718\": \"pier\",\n      \"719\": \"piggy bank, penny bank\",\n      \"720\": \"pill bottle\",\n      \"721\": \"pillow\",\n      \"722\": \"ping-pong ball\",\n      \"723\": \"pinwheel\",\n      \"724\": \"pirate, pirate ship\",\n      \"725\": \"pitcher, ewer\",\n      \"726\": \"plane, carpenter's plane, woodworking plane\",\n      \"727\": \"planetarium\",\n      \"728\": \"plastic bag\",\n      \"729\": \"plate rack\",\n      \"730\": \"plow, plough\",\n      \"731\": \"plunger, plumber's helper\",\n      \"732\": \"Polaroid camera, Polaroid Land camera\",\n      \"733\": \"pole\",\n      \"734\": \"police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria\",\n      \"735\": \"poncho\",\n      \"736\": \"pool table, billiard table, snooker table\",\n      \"737\": \"pop bottle, soda bottle\",\n      \"738\": \"pot, flowerpot\",\n      \"739\": \"potter's wheel\",\n      \"740\": \"power drill\",\n      \"741\": \"prayer rug, prayer mat\",\n      \"742\": \"printer\",\n      \"743\": \"prison, prison house\",\n      \"744\": \"projectile, missile\",\n      \"745\": \"projector\",\n      \"746\": \"puck, hockey puck\",\n      \"747\": \"punching bag, punch bag, punching ball, punchball\",\n      \"748\": \"purse\",\n      \"749\": \"quill, quill pen\",\n      \"750\": \"quilt, comforter, comfort, puff\",\n      \"751\": \"racer, race car, racing car\",\n      \"752\": \"racket, racquet\",\n      \"753\": \"radiator\",\n      \"754\": \"radio, wireless\",\n      \"755\": \"radio telescope, radio reflector\",\n      \"756\": \"rain barrel\",\n      \"757\": \"recreational vehicle, RV, R.V.\",\n      \"758\": \"reel\",\n      \"759\": \"reflex camera\",\n      \"760\": \"refrigerator, icebox\",\n      \"761\": \"remote control, remote\",\n      \"762\": \"restaurant, eating house, eating place, eatery\",\n      \"763\": \"revolver, six-gun, six-shooter\",\n      \"764\": \"rifle\",\n      \"765\": \"rocking chair, rocker\",\n      \"766\": \"rotisserie\",\n      \"767\": \"rubber eraser, rubber, pencil eraser\",\n      \"768\": \"rugby ball\",\n      \"769\": \"rule, ruler\",\n      \"770\": \"running shoe\",\n      \"771\": \"safe\",\n      \"772\": \"safety pin\",\n      \"773\": \"saltshaker, salt shaker\",\n      \"774\": \"sandal\",\n      \"775\": \"sarong\",\n      \"776\": \"sax, saxophone\",\n      \"777\": \"scabbard\",\n      \"778\": \"scale, weighing machine\",\n      \"779\": \"school bus\",\n      \"780\": \"schooner\",\n      \"781\": \"scoreboard\",\n      \"782\": \"screen, CRT screen\",\n      \"783\": \"screw\",\n      \"784\": \"screwdriver\",\n      \"785\": \"seat belt, seatbelt\",\n      \"786\": \"sewing machine\",\n      \"787\": \"shield, buckler\",\n      \"788\": \"shoe shop, shoe-shop, shoe store\",\n      \"789\": \"shoji\",\n      \"790\": \"shopping basket\",\n      \"791\": \"shopping cart\",\n      \"792\": \"shovel\",\n      \"793\": \"shower cap\",\n      \"794\": \"shower curtain\",\n      \"795\": \"ski\",\n      \"796\": \"ski mask\",\n      \"797\": \"sleeping bag\",\n      \"798\": \"slide rule, slipstick\",\n      \"799\": \"sliding door\",\n      \"800\": \"slot, one-armed bandit\",\n      \"801\": \"snorkel\",\n      \"802\": \"snowmobile\",\n      \"803\": \"snowplow, snowplough\",\n      \"804\": \"soap dispenser\",\n      \"805\": \"soccer ball\",\n      \"806\": \"sock\",\n      \"807\": \"solar dish, solar collector, solar furnace\",\n      \"808\": \"sombrero\",\n      \"809\": \"soup bowl\",\n      \"810\": \"space bar\",\n      \"811\": \"space heater\",\n      \"812\": \"space shuttle\",\n      \"813\": \"spatula\",\n      \"814\": \"speedboat\",\n      \"815\": \"spider web, spider's web\",\n      \"816\": \"spindle\",\n      \"817\": \"sports car, sport car\",\n      \"818\": \"spotlight, spot\",\n      \"819\": \"stage\",\n      \"820\": \"steam locomotive\",\n      \"821\": \"steel arch bridge\",\n      \"822\": \"steel drum\",\n      \"823\": \"stethoscope\",\n      \"824\": \"stole\",\n      \"825\": \"stone wall\",\n      \"826\": \"stopwatch, stop watch\",\n      \"827\": \"stove\",\n      \"828\": \"strainer\",\n      \"829\": \"streetcar, tram, tramcar, trolley, trolley car\",\n      \"830\": \"stretcher\",\n      \"831\": \"studio couch, day bed\",\n      \"832\": \"stupa, tope\",\n      \"833\": \"submarine, pigboat, sub, U-boat\",\n      \"834\": \"suit, suit of clothes\",\n      \"835\": \"sundial\",\n      \"836\": \"sunglass\",\n      \"837\": \"sunglasses, dark glasses, shades\",\n      \"838\": \"sunscreen, sunblock, sun blocker\",\n      \"839\": \"suspension bridge\",\n      \"840\": \"swab, swob, mop\",\n      \"841\": \"sweatshirt\",\n      \"842\": \"swimming trunks, bathing trunks\",\n      \"843\": \"swing\",\n      \"844\": \"switch, electric switch, electrical switch\",\n      \"845\": \"syringe\",\n      \"846\": \"table lamp\",\n      \"847\": \"tank, army tank, armored combat vehicle, armoured combat vehicle\",\n      \"848\": \"tape player\",\n      \"849\": \"teapot\",\n      \"850\": \"teddy, teddy bear\",\n      \"851\": \"television, television system\",\n      \"852\": \"tennis ball\",\n      \"853\": \"thatch, thatched roof\",\n      \"854\": \"theater curtain, theatre curtain\",\n      \"855\": \"thimble\",\n      \"856\": \"thresher, thrasher, threshing machine\",\n      \"857\": \"throne\",\n      \"858\": \"tile roof\",\n      \"859\": \"toaster\",\n      \"860\": \"tobacco shop, tobacconist shop, tobacconist\",\n      \"861\": \"toilet seat\",\n      \"862\": \"torch\",\n      \"863\": \"totem pole\",\n      \"864\": \"tow truck, tow car, wrecker\",\n      \"865\": \"toyshop\",\n      \"866\": \"tractor\",\n      \"867\": \"trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi\",\n      \"868\": \"tray\",\n      \"869\": \"trench coat\",\n      \"870\": \"tricycle, trike, velocipede\",\n      \"871\": \"trimaran\",\n      \"872\": \"tripod\",\n      \"873\": \"triumphal arch\",\n      \"874\": \"trolleybus, trolley coach, trackless trolley\",\n      \"875\": \"trombone\",\n      \"876\": \"tub, vat\",\n      \"877\": \"turnstile\",\n      \"878\": \"typewriter keyboard\",\n      \"879\": \"umbrella\",\n      \"880\": \"unicycle, monocycle\",\n      \"881\": \"upright, upright piano\",\n      \"882\": \"vacuum, vacuum cleaner\",\n      \"883\": \"vase\",\n      \"884\": \"vault\",\n      \"885\": \"velvet\",\n      \"886\": \"vending machine\",\n      \"887\": \"vestment\",\n      \"888\": \"viaduct\",\n      \"889\": \"violin, fiddle\",\n      \"890\": \"volleyball\",\n      \"891\": \"waffle iron\",\n      \"892\": \"wall clock\",\n      \"893\": \"wallet, billfold, notecase, pocketbook\",\n      \"894\": \"wardrobe, closet, press\",\n      \"895\": \"warplane, military plane\",\n      \"896\": \"washbasin, handbasin, washbowl, lavabo, wash-hand basin\",\n      \"897\": \"washer, automatic washer, washing machine\",\n      \"898\": \"water bottle\",\n      \"899\": \"water jug\",\n      \"900\": \"water tower\",\n      \"901\": \"whiskey jug\",\n      \"902\": \"whistle\",\n      \"903\": \"wig\",\n      \"904\": \"window screen\",\n      \"905\": \"window shade\",\n      \"906\": \"Windsor tie\",\n      \"907\": \"wine bottle\",\n      \"908\": \"wing\",\n      \"909\": \"wok\",\n      \"910\": \"wooden spoon\",\n      \"911\": \"wool, woolen, woollen\",\n      \"912\": \"worm fence, snake fence, snake-rail fence, Virginia fence\",\n      \"913\": \"wreck\",\n      \"914\": \"yawl\",\n      \"915\": \"yurt\",\n      \"916\": \"web site, website, internet site, site\",\n      \"917\": \"comic book\",\n      \"918\": \"crossword puzzle, crossword\",\n      \"919\": \"street sign\",\n      \"920\": \"traffic light, traffic signal, stoplight\",\n      \"921\": \"book jacket, dust cover, dust jacket, dust wrapper\",\n      \"922\": \"menu\",\n      \"923\": \"plate\",\n      \"924\": \"guacamole\",\n      \"925\": \"consomme\",\n      \"926\": \"hot pot, hotpot\",\n      \"927\": \"trifle\",\n      \"928\": \"ice cream, icecream\",\n      \"929\": \"ice lolly, lolly, lollipop, popsicle\",\n      \"930\": \"French loaf\",\n      \"931\": \"bagel, beigel\",\n      \"932\": \"pretzel\",\n      \"933\": \"cheeseburger\",\n      \"934\": \"hotdog, hot dog, red hot\",\n      \"935\": \"mashed potato\",\n      \"936\": \"head cabbage\",\n      \"937\": \"broccoli\",\n      \"938\": \"cauliflower\",\n      \"939\": \"zucchini, courgette\",\n      \"940\": \"spaghetti squash\",\n      \"941\": \"acorn squash\",\n      \"942\": \"butternut squash\",\n      \"943\": \"cucumber, cuke\",\n      \"944\": \"artichoke, globe artichoke\",\n      \"945\": \"bell pepper\",\n      \"946\": \"cardoon\",\n      \"947\": \"mushroom\",\n      \"948\": \"Granny Smith\",\n      \"949\": \"strawberry\",\n      \"950\": \"orange\",\n      \"951\": \"lemon\",\n      \"952\": \"fig\",\n      \"953\": \"pineapple, ananas\",\n      \"954\": \"banana\",\n      \"955\": \"jackfruit, jak, jack\",\n      \"956\": \"custard apple\",\n      \"957\": \"pomegranate\",\n      \"958\": \"hay\",\n      \"959\": \"carbonara\",\n      \"960\": \"chocolate sauce, chocolate syrup\",\n      \"961\": \"dough\",\n      \"962\": \"meat loaf, meatloaf\",\n      \"963\": \"pizza, pizza pie\",\n      \"964\": \"potpie\",\n      \"965\": \"burrito\",\n      \"966\": \"red wine\",\n      \"967\": \"espresso\",\n      \"968\": \"cup\",\n      \"969\": \"eggnog\",\n      \"970\": \"alp\",\n      \"971\": \"bubble\",\n      \"972\": \"cliff, drop, drop-off\",\n      \"973\": \"coral reef\",\n      \"974\": \"geyser\",\n      \"975\": \"lakeside, lakeshore\",\n      \"976\": \"promontory, headland, head, foreland\",\n      \"977\": \"sandbar, sand bar\",\n      \"978\": \"seashore, coast, seacoast, sea-coast\",\n      \"979\": \"valley, vale\",\n      \"980\": \"volcano\",\n      \"981\": \"ballplayer, baseball player\",\n      \"982\": \"groom, bridegroom\",\n      \"983\": \"scuba diver\",\n      \"984\": \"rapeseed\",\n      \"985\": \"daisy\",\n      \"986\": \"yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripedium parviflorum\",\n      \"987\": \"corn\",\n      \"988\": \"acorn\",\n      \"989\": \"hip, rose hip, rosehip\",\n      \"990\": \"buckeye, horse chestnut, conker\",\n      \"991\": \"coral fungus\",\n      \"992\": \"agaric\",\n      \"993\": \"gyromitra\",\n      \"994\": \"stinkhorn, carrion fungus\",\n      \"995\": \"earthstar\",\n      \"996\": \"hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa\",\n      \"997\": \"bolete\",\n      \"998\": \"ear, spike, capitulum\",\n      \"999\": \"toilet tissue, toilet paper, bathroom tissue\"\n    },\n    \"image_size\": 224,\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 3072,\n    \"is_decoder\": false,\n    \"is_encoder_decoder\": false,\n    \"label2id\": {\n      \"Afghan hound, Afghan\": 160,\n      \"African chameleon, Chamaeleo chamaeleon\": 47,\n      \"African crocodile, Nile crocodile, Crocodylus niloticus\": 49,\n      \"African elephant, Loxodonta africana\": 386,\n      \"African grey, African gray, Psittacus erithacus\": 87,\n      \"African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus\": 275,\n      \"Airedale, Airedale terrier\": 191,\n      \"American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier\": 180,\n      \"American alligator, Alligator mississipiensis\": 50,\n      \"American black bear, black bear, Ursus americanus, Euarctos americanus\": 295,\n      \"American chameleon, anole, Anolis carolinensis\": 40,\n      \"American coot, marsh hen, mud hen, water hen, Fulica americana\": 137,\n      \"American egret, great white heron, Egretta albus\": 132,\n      \"American lobster, Northern lobster, Maine lobster, Homarus americanus\": 122,\n      \"Angora, Angora rabbit\": 332,\n      \"Appenzeller\": 240,\n      \"Arabian camel, dromedary, Camelus dromedarius\": 354,\n      \"Arctic fox, white fox, Alopex lagopus\": 279,\n      \"Australian terrier\": 193,\n      \"Band Aid\": 419,\n      \"Bedlington terrier\": 181,\n      \"Bernese mountain dog\": 239,\n      \"Blenheim spaniel\": 156,\n      \"Border collie\": 232,\n      \"Border terrier\": 182,\n      \"Boston bull, Boston terrier\": 195,\n      \"Bouvier des Flandres, Bouviers des Flandres\": 233,\n      \"Brabancon griffon\": 262,\n      \"Brittany spaniel\": 215,\n      \"CD player\": 485,\n      \"Cardigan, Cardigan Welsh corgi\": 264,\n      \"Chesapeake Bay retriever\": 209,\n      \"Chihuahua\": 151,\n      \"Christmas stocking\": 496,\n      \"Crock Pot\": 521,\n      \"Dandie Dinmont, Dandie Dinmont terrier\": 194,\n      \"Doberman, Doberman pinscher\": 236,\n      \"Dungeness crab, Cancer magister\": 118,\n      \"Dutch oven\": 544,\n      \"Egyptian cat\": 285,\n      \"English foxhound\": 167,\n      \"English setter\": 212,\n      \"English springer, English springer spaniel\": 217,\n      \"EntleBucher\": 241,\n      \"Eskimo dog, husky\": 248,\n      \"European fire salamander, Salamandra salamandra\": 25,\n      \"European gallinule, Porphyrio porphyrio\": 136,\n      \"French bulldog\": 245,\n      \"French horn, horn\": 566,\n      \"French loaf\": 930,\n      \"German shepherd, German shepherd dog, German police dog, alsatian\": 235,\n      \"German short-haired pointer\": 210,\n      \"Gila monster, Heloderma suspectum\": 45,\n      \"Gordon setter\": 214,\n      \"Granny Smith\": 948,\n      \"Great Dane\": 246,\n      \"Great Pyrenees\": 257,\n      \"Greater Swiss Mountain dog\": 238,\n      \"Ibizan hound, Ibizan Podenco\": 173,\n      \"Indian cobra, Naja naja\": 63,\n      \"Indian elephant, Elephas maximus\": 385,\n      \"Irish setter, red setter\": 213,\n      \"Irish terrier\": 184,\n      \"Irish water spaniel\": 221,\n      \"Irish wolfhound\": 170,\n      \"Italian greyhound\": 171,\n      \"Japanese spaniel\": 152,\n      \"Kerry blue terrier\": 183,\n      \"Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis\": 48,\n      \"Labrador retriever\": 208,\n      \"Lakeland terrier\": 189,\n      \"Leonberg\": 255,\n      \"Lhasa, Lhasa apso\": 204,\n      \"Loafer\": 630,\n      \"Madagascar cat, ring-tailed lemur, Lemur catta\": 383,\n      \"Maltese dog, Maltese terrier, Maltese\": 153,\n      \"Mexican hairless\": 268,\n      \"Model T\": 661,\n      \"Newfoundland, Newfoundland dog\": 256,\n      \"Norfolk terrier\": 185,\n      \"Norwegian elkhound, elkhound\": 174,\n      \"Norwich terrier\": 186,\n      \"Old English sheepdog, bobtail\": 229,\n      \"Pekinese, Pekingese, Peke\": 154,\n      \"Pembroke, Pembroke Welsh corgi\": 263,\n      \"Persian cat\": 283,\n      \"Petri dish\": 712,\n      \"Polaroid camera, Polaroid Land camera\": 732,\n      \"Pomeranian\": 259,\n      \"Rhodesian ridgeback\": 159,\n      \"Rottweiler\": 234,\n      \"Saint Bernard, St Bernard\": 247,\n      \"Saluki, gazelle hound\": 176,\n      \"Samoyed, Samoyede\": 258,\n      \"Scotch terrier, Scottish terrier, Scottie\": 199,\n      \"Scottish deerhound, deerhound\": 177,\n      \"Sealyham terrier, Sealyham\": 190,\n      \"Shetland sheepdog, Shetland sheep dog, Shetland\": 230,\n      \"Shih-Tzu\": 155,\n      \"Siamese cat, Siamese\": 284,\n      \"Siberian husky\": 250,\n      \"Staffordshire bullterrier, Staffordshire bull terrier\": 179,\n      \"Sussex spaniel\": 220,\n      \"Tibetan mastiff\": 244,\n      \"Tibetan terrier, chrysanthemum dog\": 200,\n      \"Walker hound, Walker foxhound\": 166,\n      \"Weimaraner\": 178,\n      \"Welsh springer spaniel\": 218,\n      \"West Highland white terrier\": 203,\n      \"Windsor tie\": 906,\n      \"Yorkshire terrier\": 187,\n      \"abacus\": 398,\n      \"abaya\": 399,\n      \"academic gown, academic robe, judge's robe\": 400,\n      \"accordion, piano accordion, squeeze box\": 401,\n      \"acorn\": 988,\n      \"acorn squash\": 941,\n      \"acoustic guitar\": 402,\n      \"admiral\": 321,\n      \"affenpinscher, monkey pinscher, monkey dog\": 252,\n      \"agama\": 42,\n      \"agaric\": 992,\n      \"aircraft carrier, carrier, flattop, attack aircraft carrier\": 403,\n      \"airliner\": 404,\n      \"airship, dirigible\": 405,\n      \"albatross, mollymawk\": 146,\n      \"alligator lizard\": 44,\n      \"alp\": 970,\n      \"altar\": 406,\n      \"ambulance\": 407,\n      \"amphibian, amphibious vehicle\": 408,\n      \"analog clock\": 409,\n      \"anemone fish\": 393,\n      \"ant, emmet, pismire\": 310,\n      \"apiary, bee house\": 410,\n      \"apron\": 411,\n      \"armadillo\": 363,\n      \"artichoke, globe artichoke\": 944,\n      \"ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin\": 412,\n      \"assault rifle, assault gun\": 413,\n      \"axolotl, mud puppy, Ambystoma mexicanum\": 29,\n      \"baboon\": 372,\n      \"backpack, back pack, knapsack, packsack, rucksack, haversack\": 414,\n      \"badger\": 362,\n      \"bagel, beigel\": 931,\n      \"bakery, bakeshop, bakehouse\": 415,\n      \"balance beam, beam\": 416,\n      \"bald eagle, American eagle, Haliaeetus leucocephalus\": 22,\n      \"balloon\": 417,\n      \"ballplayer, baseball player\": 981,\n      \"ballpoint, ballpoint pen, ballpen, Biro\": 418,\n      \"banana\": 954,\n      \"banded gecko\": 38,\n      \"banjo\": 420,\n      \"bannister, banister, balustrade, balusters, handrail\": 421,\n      \"barbell\": 422,\n      \"barber chair\": 423,\n      \"barbershop\": 424,\n      \"barn\": 425,\n      \"barn spider, Araneus cavaticus\": 73,\n      \"barometer\": 426,\n      \"barracouta, snoek\": 389,\n      \"barrel, cask\": 427,\n      \"barrow, garden cart, lawn cart, wheelbarrow\": 428,\n      \"baseball\": 429,\n      \"basenji\": 253,\n      \"basketball\": 430,\n      \"basset, basset hound\": 161,\n      \"bassinet\": 431,\n      \"bassoon\": 432,\n      \"bath towel\": 434,\n      \"bathing cap, swimming cap\": 433,\n      \"bathtub, bathing tub, bath, tub\": 435,\n      \"beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon\": 436,\n      \"beacon, lighthouse, beacon light, pharos\": 437,\n      \"beagle\": 162,\n      \"beaker\": 438,\n      \"bearskin, busby, shako\": 439,\n      \"beaver\": 337,\n      \"bee\": 309,\n      \"bee eater\": 92,\n      \"beer bottle\": 440,\n      \"beer glass\": 441,\n      \"bell cote, bell cot\": 442,\n      \"bell pepper\": 945,\n      \"bib\": 443,\n      \"bicycle-built-for-two, tandem bicycle, tandem\": 444,\n      \"bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis\": 349,\n      \"bikini, two-piece\": 445,\n      \"binder, ring-binder\": 446,\n      \"binoculars, field glasses, opera glasses\": 447,\n      \"birdhouse\": 448,\n      \"bison\": 347,\n      \"bittern\": 133,\n      \"black and gold garden spider, Argiope aurantia\": 72,\n      \"black grouse\": 80,\n      \"black stork, Ciconia nigra\": 128,\n      \"black swan, Cygnus atratus\": 100,\n      \"black widow, Latrodectus mactans\": 75,\n      \"black-and-tan coonhound\": 165,\n      \"black-footed ferret, ferret, Mustela nigripes\": 359,\n      \"bloodhound, sleuthhound\": 163,\n      \"bluetick\": 164,\n      \"boa constrictor, Constrictor constrictor\": 61,\n      \"boathouse\": 449,\n      \"bobsled, bobsleigh, bob\": 450,\n      \"bolete\": 997,\n      \"bolo tie, bolo, bola tie, bola\": 451,\n      \"bonnet, poke bonnet\": 452,\n      \"book jacket, dust cover, dust jacket, dust wrapper\": 921,\n      \"bookcase\": 453,\n      \"bookshop, bookstore, bookstall\": 454,\n      \"borzoi, Russian wolfhound\": 169,\n      \"bottlecap\": 455,\n      \"bow\": 456,\n      \"bow tie, bow-tie, bowtie\": 457,\n      \"box turtle, box tortoise\": 37,\n      \"boxer\": 242,\n      \"brain coral\": 109,\n      \"brambling, Fringilla montifringilla\": 10,\n      \"brass, memorial tablet, plaque\": 458,\n      \"brassiere, bra, bandeau\": 459,\n      \"breakwater, groin, groyne, mole, bulwark, seawall, jetty\": 460,\n      \"breastplate, aegis, egis\": 461,\n      \"briard\": 226,\n      \"broccoli\": 937,\n      \"broom\": 462,\n      \"brown bear, bruin, Ursus arctos\": 294,\n      \"bubble\": 971,\n      \"bucket, pail\": 463,\n      \"buckeye, horse chestnut, conker\": 990,\n      \"buckle\": 464,\n      \"bulbul\": 16,\n      \"bull mastiff\": 243,\n      \"bullet train, bullet\": 466,\n      \"bulletproof vest\": 465,\n      \"bullfrog, Rana catesbeiana\": 30,\n      \"burrito\": 965,\n      \"bustard\": 138,\n      \"butcher shop, meat market\": 467,\n      \"butternut squash\": 942,\n      \"cab, hack, taxi, taxicab\": 468,\n      \"cabbage butterfly\": 324,\n      \"cairn, cairn terrier\": 192,\n      \"caldron, cauldron\": 469,\n      \"can opener, tin opener\": 473,\n      \"candle, taper, wax light\": 470,\n      \"cannon\": 471,\n      \"canoe\": 472,\n      \"capuchin, ringtail, Cebus capucinus\": 378,\n      \"car mirror\": 475,\n      \"car wheel\": 479,\n      \"carbonara\": 959,\n      \"cardigan\": 474,\n      \"cardoon\": 946,\n      \"carousel, carrousel, merry-go-round, roundabout, whirligig\": 476,\n      \"carpenter's kit, tool kit\": 477,\n      \"carton\": 478,\n      \"cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM\": 480,\n      \"cassette\": 481,\n      \"cassette player\": 482,\n      \"castle\": 483,\n      \"catamaran\": 484,\n      \"cauliflower\": 938,\n      \"cello, violoncello\": 486,\n      \"cellular telephone, cellular phone, cellphone, cell, mobile phone\": 487,\n      \"centipede\": 79,\n      \"chain\": 488,\n      \"chain mail, ring mail, mail, chain armor, chain armour, ring armor, ring armour\": 490,\n      \"chain saw, chainsaw\": 491,\n      \"chainlink fence\": 489,\n      \"chambered nautilus, pearly nautilus, nautilus\": 117,\n      \"cheeseburger\": 933,\n      \"cheetah, chetah, Acinonyx jubatus\": 293,\n      \"chest\": 492,\n      \"chickadee\": 19,\n      \"chiffonier, commode\": 493,\n      \"chime, bell, gong\": 494,\n      \"chimpanzee, chimp, Pan troglodytes\": 367,\n      \"china cabinet, china closet\": 495,\n      \"chiton, coat-of-mail shell, sea cradle, polyplacophore\": 116,\n      \"chocolate sauce, chocolate syrup\": 960,\n      \"chow, chow chow\": 260,\n      \"church, church building\": 497,\n      \"cicada, cicala\": 316,\n      \"cinema, movie theater, movie theatre, movie house, picture palace\": 498,\n      \"cleaver, meat cleaver, chopper\": 499,\n      \"cliff dwelling\": 500,\n      \"cliff, drop, drop-off\": 972,\n      \"cloak\": 501,\n      \"clog, geta, patten, sabot\": 502,\n      \"clumber, clumber spaniel\": 216,\n      \"cock\": 7,\n      \"cocker spaniel, English cocker spaniel, cocker\": 219,\n      \"cockroach, roach\": 314,\n      \"cocktail shaker\": 503,\n      \"coffee mug\": 504,\n      \"coffeepot\": 505,\n      \"coho, cohoe, coho salmon, blue jack, silver salmon, Oncorhynchus kisutch\": 391,\n      \"coil, spiral, volute, whorl, helix\": 506,\n      \"collie\": 231,\n      \"colobus, colobus monkey\": 375,\n      \"combination lock\": 507,\n      \"comic book\": 917,\n      \"common iguana, iguana, Iguana iguana\": 39,\n      \"common newt, Triturus vulgaris\": 26,\n      \"computer keyboard, keypad\": 508,\n      \"conch\": 112,\n      \"confectionery, confectionary, candy store\": 509,\n      \"consomme\": 925,\n      \"container ship, containership, container vessel\": 510,\n      \"convertible\": 511,\n      \"coral fungus\": 991,\n      \"coral reef\": 973,\n      \"corkscrew, bottle screw\": 512,\n      \"corn\": 987,\n      \"cornet, horn, trumpet, trump\": 513,\n      \"coucal\": 91,\n      \"cougar, puma, catamount, mountain lion, painter, panther, Felis concolor\": 286,\n      \"cowboy boot\": 514,\n      \"cowboy hat, ten-gallon hat\": 515,\n      \"coyote, prairie wolf, brush wolf, Canis latrans\": 272,\n      \"cradle\": 516,\n      \"crane\": 517,\n      \"crash helmet\": 518,\n      \"crate\": 519,\n      \"crayfish, crawfish, crawdad, crawdaddy\": 124,\n      \"crib, cot\": 520,\n      \"cricket\": 312,\n      \"croquet ball\": 522,\n      \"crossword puzzle, crossword\": 918,\n      \"crutch\": 523,\n      \"cucumber, cuke\": 943,\n      \"cuirass\": 524,\n      \"cup\": 968,\n      \"curly-coated retriever\": 206,\n      \"custard apple\": 956,\n      \"daisy\": 985,\n      \"dalmatian, coach dog, carriage dog\": 251,\n      \"dam, dike, dyke\": 525,\n      \"damselfly\": 320,\n      \"desk\": 526,\n      \"desktop computer\": 527,\n      \"dhole, Cuon alpinus\": 274,\n      \"dial telephone, dial phone\": 528,\n      \"diamondback, diamondback rattlesnake, Crotalus adamanteus\": 67,\n      \"diaper, nappy, napkin\": 529,\n      \"digital clock\": 530,\n      \"digital watch\": 531,\n      \"dingo, warrigal, warragal, Canis dingo\": 273,\n      \"dining table, board\": 532,\n      \"dishrag, dishcloth\": 533,\n      \"dishwasher, dish washer, dishwashing machine\": 534,\n      \"disk brake, disc brake\": 535,\n      \"dock, dockage, docking facility\": 536,\n      \"dogsled, dog sled, dog sleigh\": 537,\n      \"dome\": 538,\n      \"doormat, welcome mat\": 539,\n      \"dough\": 961,\n      \"dowitcher\": 142,\n      \"dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk\": 319,\n      \"drake\": 97,\n      \"drilling platform, offshore rig\": 540,\n      \"drum, membranophone, tympan\": 541,\n      \"drumstick\": 542,\n      \"dugong, Dugong dugon\": 149,\n      \"dumbbell\": 543,\n      \"dung beetle\": 305,\n      \"ear, spike, capitulum\": 998,\n      \"earthstar\": 995,\n      \"echidna, spiny anteater, anteater\": 102,\n      \"eel\": 390,\n      \"eft\": 27,\n      \"eggnog\": 969,\n      \"electric fan, blower\": 545,\n      \"electric guitar\": 546,\n      \"electric locomotive\": 547,\n      \"electric ray, crampfish, numbfish, torpedo\": 5,\n      \"entertainment center\": 548,\n      \"envelope\": 549,\n      \"espresso\": 967,\n      \"espresso maker\": 550,\n      \"face powder\": 551,\n      \"feather boa, boa\": 552,\n      \"fiddler crab\": 120,\n      \"fig\": 952,\n      \"file, file cabinet, filing cabinet\": 553,\n      \"fire engine, fire truck\": 555,\n      \"fire screen, fireguard\": 556,\n      \"fireboat\": 554,\n      \"flagpole, flagstaff\": 557,\n      \"flamingo\": 130,\n      \"flat-coated retriever\": 205,\n      \"flatworm, platyhelminth\": 110,\n      \"flute, transverse flute\": 558,\n      \"fly\": 308,\n      \"folding chair\": 559,\n      \"football helmet\": 560,\n      \"forklift\": 561,\n      \"fountain\": 562,\n      \"fountain pen\": 563,\n      \"four-poster\": 564,\n      \"fox squirrel, eastern fox squirrel, Sciurus niger\": 335,\n      \"freight car\": 565,\n      \"frilled lizard, Chlamydosaurus kingi\": 43,\n      \"frying pan, frypan, skillet\": 567,\n      \"fur coat\": 568,\n      \"gar, garfish, garpike, billfish, Lepisosteus osseus\": 395,\n      \"garbage truck, dustcart\": 569,\n      \"garden spider, Aranea diademata\": 74,\n      \"garter snake, grass snake\": 57,\n      \"gas pump, gasoline pump, petrol pump, island dispenser\": 571,\n      \"gasmask, respirator, gas helmet\": 570,\n      \"gazelle\": 353,\n      \"geyser\": 974,\n      \"giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca\": 388,\n      \"giant schnauzer\": 197,\n      \"gibbon, Hylobates lar\": 368,\n      \"go-kart\": 573,\n      \"goblet\": 572,\n      \"golden retriever\": 207,\n      \"goldfinch, Carduelis carduelis\": 11,\n      \"goldfish, Carassius auratus\": 1,\n      \"golf ball\": 574,\n      \"golfcart, golf cart\": 575,\n      \"gondola\": 576,\n      \"gong, tam-tam\": 577,\n      \"goose\": 99,\n      \"gorilla, Gorilla gorilla\": 366,\n      \"gown\": 578,\n      \"grand piano, grand\": 579,\n      \"grasshopper, hopper\": 311,\n      \"great grey owl, great gray owl, Strix nebulosa\": 24,\n      \"great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias\": 2,\n      \"green lizard, Lacerta viridis\": 46,\n      \"green mamba\": 64,\n      \"green snake, grass snake\": 55,\n      \"greenhouse, nursery, glasshouse\": 580,\n      \"grey fox, gray fox, Urocyon cinereoargenteus\": 280,\n      \"grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus\": 147,\n      \"grille, radiator grille\": 581,\n      \"grocery store, grocery, food market, market\": 582,\n      \"groenendael\": 224,\n      \"groom, bridegroom\": 982,\n      \"ground beetle, carabid beetle\": 302,\n      \"guacamole\": 924,\n      \"guenon, guenon monkey\": 370,\n      \"guillotine\": 583,\n      \"guinea pig, Cavia cobaya\": 338,\n      \"gyromitra\": 993,\n      \"hair slide\": 584,\n      \"hair spray\": 585,\n      \"half track\": 586,\n      \"hammer\": 587,\n      \"hammerhead, hammerhead shark\": 4,\n      \"hamper\": 588,\n      \"hamster\": 333,\n      \"hand blower, blow dryer, blow drier, hair dryer, hair drier\": 589,\n      \"hand-held computer, hand-held microcomputer\": 590,\n      \"handkerchief, hankie, hanky, hankey\": 591,\n      \"hard disc, hard disk, fixed disk\": 592,\n      \"hare\": 331,\n      \"harmonica, mouth organ, harp, mouth harp\": 593,\n      \"harp\": 594,\n      \"hartebeest\": 351,\n      \"harvester, reaper\": 595,\n      \"harvestman, daddy longlegs, Phalangium opilio\": 70,\n      \"hatchet\": 596,\n      \"hay\": 958,\n      \"head cabbage\": 936,\n      \"hen\": 8,\n      \"hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa\": 996,\n      \"hermit crab\": 125,\n      \"hip, rose hip, rosehip\": 989,\n      \"hippopotamus, hippo, river horse, Hippopotamus amphibius\": 344,\n      \"hog, pig, grunter, squealer, Sus scrofa\": 341,\n      \"hognose snake, puff adder, sand viper\": 54,\n      \"holster\": 597,\n      \"home theater, home theatre\": 598,\n      \"honeycomb\": 599,\n      \"hook, claw\": 600,\n      \"hoopskirt, crinoline\": 601,\n      \"horizontal bar, high bar\": 602,\n      \"hornbill\": 93,\n      \"horned viper, cerastes, sand viper, horned asp, Cerastes cornutus\": 66,\n      \"horse cart, horse-cart\": 603,\n      \"hot pot, hotpot\": 926,\n      \"hotdog, hot dog, red hot\": 934,\n      \"hourglass\": 604,\n      \"house finch, linnet, Carpodacus mexicanus\": 12,\n      \"howler monkey, howler\": 379,\n      \"hummingbird\": 94,\n      \"hyena, hyaena\": 276,\n      \"iPod\": 605,\n      \"ibex, Capra ibex\": 350,\n      \"ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus\": 296,\n      \"ice cream, icecream\": 928,\n      \"ice lolly, lolly, lollipop, popsicle\": 929,\n      \"impala, Aepyceros melampus\": 352,\n      \"indigo bunting, indigo finch, indigo bird, Passerina cyanea\": 14,\n      \"indri, indris, Indri indri, Indri brevicaudatus\": 384,\n      \"iron, smoothing iron\": 606,\n      \"isopod\": 126,\n      \"jacamar\": 95,\n      \"jack-o'-lantern\": 607,\n      \"jackfruit, jak, jack\": 955,\n      \"jaguar, panther, Panthera onca, Felis onca\": 290,\n      \"jay\": 17,\n      \"jean, blue jean, denim\": 608,\n      \"jeep, landrover\": 609,\n      \"jellyfish\": 107,\n      \"jersey, T-shirt, tee shirt\": 610,\n      \"jigsaw puzzle\": 611,\n      \"jinrikisha, ricksha, rickshaw\": 612,\n      \"joystick\": 613,\n      \"junco, snowbird\": 13,\n      \"keeshond\": 261,\n      \"kelpie\": 227,\n      \"killer whale, killer, orca, grampus, sea wolf, Orcinus orca\": 148,\n      \"kimono\": 614,\n      \"king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodes camtschatica\": 121,\n      \"king penguin, Aptenodytes patagonica\": 145,\n      \"king snake, kingsnake\": 56,\n      \"kit fox, Vulpes macrotis\": 278,\n      \"kite\": 21,\n      \"knee pad\": 615,\n      \"knot\": 616,\n      \"koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus\": 105,\n      \"komondor\": 228,\n      \"kuvasz\": 222,\n      \"lab coat, laboratory coat\": 617,\n      \"lacewing, lacewing fly\": 318,\n      \"ladle\": 618,\n      \"ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle\": 301,\n      \"lakeside, lakeshore\": 975,\n      \"lampshade, lamp shade\": 619,\n      \"langur\": 374,\n      \"laptop, laptop computer\": 620,\n      \"lawn mower, mower\": 621,\n      \"leaf beetle, chrysomelid\": 304,\n      \"leafhopper\": 317,\n      \"leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea\": 34,\n      \"lemon\": 951,\n      \"lens cap, lens cover\": 622,\n      \"leopard, Panthera pardus\": 288,\n      \"lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens\": 387,\n      \"letter opener, paper knife, paperknife\": 623,\n      \"library\": 624,\n      \"lifeboat\": 625,\n      \"lighter, light, igniter, ignitor\": 626,\n      \"limousine, limo\": 627,\n      \"limpkin, Aramus pictus\": 135,\n      \"liner, ocean liner\": 628,\n      \"lion, king of beasts, Panthera leo\": 291,\n      \"lionfish\": 396,\n      \"lipstick, lip rouge\": 629,\n      \"little blue heron, Egretta caerulea\": 131,\n      \"llama\": 355,\n      \"loggerhead, loggerhead turtle, Caretta caretta\": 33,\n      \"long-horned beetle, longicorn, longicorn beetle\": 303,\n      \"lorikeet\": 90,\n      \"lotion\": 631,\n      \"loudspeaker, speaker, speaker unit, loudspeaker system, speaker system\": 632,\n      \"loupe, jeweler's loupe\": 633,\n      \"lumbermill, sawmill\": 634,\n      \"lycaenid, lycaenid butterfly\": 326,\n      \"lynx, catamount\": 287,\n      \"macaque\": 373,\n      \"macaw\": 88,\n      \"magnetic compass\": 635,\n      \"magpie\": 18,\n      \"mailbag, postbag\": 636,\n      \"mailbox, letter box\": 637,\n      \"maillot\": 638,\n      \"maillot, tank suit\": 639,\n      \"malamute, malemute, Alaskan malamute\": 249,\n      \"malinois\": 225,\n      \"manhole cover\": 640,\n      \"mantis, mantid\": 315,\n      \"maraca\": 641,\n      \"marimba, xylophone\": 642,\n      \"marmoset\": 377,\n      \"marmot\": 336,\n      \"mashed potato\": 935,\n      \"mask\": 643,\n      \"matchstick\": 644,\n      \"maypole\": 645,\n      \"maze, labyrinth\": 646,\n      \"measuring cup\": 647,\n      \"meat loaf, meatloaf\": 962,\n      \"medicine chest, medicine cabinet\": 648,\n      \"meerkat, mierkat\": 299,\n      \"megalith, megalithic structure\": 649,\n      \"menu\": 922,\n      \"microphone, mike\": 650,\n      \"microwave, microwave oven\": 651,\n      \"military uniform\": 652,\n      \"milk can\": 653,\n      \"miniature pinscher\": 237,\n      \"miniature poodle\": 266,\n      \"miniature schnauzer\": 196,\n      \"minibus\": 654,\n      \"miniskirt, mini\": 655,\n      \"minivan\": 656,\n      \"mink\": 357,\n      \"missile\": 657,\n      \"mitten\": 658,\n      \"mixing bowl\": 659,\n      \"mobile home, manufactured home\": 660,\n      \"modem\": 662,\n      \"monarch, monarch butterfly, milkweed butterfly, Danaus plexippus\": 323,\n      \"monastery\": 663,\n      \"mongoose\": 298,\n      \"monitor\": 664,\n      \"moped\": 665,\n      \"mortar\": 666,\n      \"mortarboard\": 667,\n      \"mosque\": 668,\n      \"mosquito net\": 669,\n      \"motor scooter, scooter\": 670,\n      \"mountain bike, all-terrain bike, off-roader\": 671,\n      \"mountain tent\": 672,\n      \"mouse, computer mouse\": 673,\n      \"mousetrap\": 674,\n      \"moving van\": 675,\n      \"mud turtle\": 35,\n      \"mushroom\": 947,\n      \"muzzle\": 676,\n      \"nail\": 677,\n      \"neck brace\": 678,\n      \"necklace\": 679,\n      \"nematode, nematode worm, roundworm\": 111,\n      \"night snake, Hypsiglena torquata\": 60,\n      \"nipple\": 680,\n      \"notebook, notebook computer\": 681,\n      \"obelisk\": 682,\n      \"oboe, hautboy, hautbois\": 683,\n      \"ocarina, sweet potato\": 684,\n      \"odometer, hodometer, mileometer, milometer\": 685,\n      \"oil filter\": 686,\n      \"orange\": 950,\n      \"orangutan, orang, orangutang, Pongo pygmaeus\": 365,\n      \"organ, pipe organ\": 687,\n      \"oscilloscope, scope, cathode-ray oscilloscope, CRO\": 688,\n      \"ostrich, Struthio camelus\": 9,\n      \"otter\": 360,\n      \"otterhound, otter hound\": 175,\n      \"overskirt\": 689,\n      \"ox\": 345,\n      \"oxcart\": 690,\n      \"oxygen mask\": 691,\n      \"oystercatcher, oyster catcher\": 143,\n      \"packet\": 692,\n      \"paddle, boat paddle\": 693,\n      \"paddlewheel, paddle wheel\": 694,\n      \"padlock\": 695,\n      \"paintbrush\": 696,\n      \"pajama, pyjama, pj's, jammies\": 697,\n      \"palace\": 698,\n      \"panpipe, pandean pipe, syrinx\": 699,\n      \"paper towel\": 700,\n      \"papillon\": 157,\n      \"parachute, chute\": 701,\n      \"parallel bars, bars\": 702,\n      \"park bench\": 703,\n      \"parking meter\": 704,\n      \"partridge\": 86,\n      \"passenger car, coach, carriage\": 705,\n      \"patas, hussar monkey, Erythrocebus patas\": 371,\n      \"patio, terrace\": 706,\n      \"pay-phone, pay-station\": 707,\n      \"peacock\": 84,\n      \"pedestal, plinth, footstall\": 708,\n      \"pelican\": 144,\n      \"pencil box, pencil case\": 709,\n      \"pencil sharpener\": 710,\n      \"perfume, essence\": 711,\n      \"photocopier\": 713,\n      \"pick, plectrum, plectron\": 714,\n      \"pickelhaube\": 715,\n      \"picket fence, paling\": 716,\n      \"pickup, pickup truck\": 717,\n      \"pier\": 718,\n      \"piggy bank, penny bank\": 719,\n      \"pill bottle\": 720,\n      \"pillow\": 721,\n      \"pineapple, ananas\": 953,\n      \"ping-pong ball\": 722,\n      \"pinwheel\": 723,\n      \"pirate, pirate ship\": 724,\n      \"pitcher, ewer\": 725,\n      \"pizza, pizza pie\": 963,\n      \"plane, carpenter's plane, woodworking plane\": 726,\n      \"planetarium\": 727,\n      \"plastic bag\": 728,\n      \"plate\": 923,\n      \"plate rack\": 729,\n      \"platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus\": 103,\n      \"plow, plough\": 730,\n      \"plunger, plumber's helper\": 731,\n      \"pole\": 733,\n      \"polecat, fitch, foulmart, foumart, Mustela putorius\": 358,\n      \"police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria\": 734,\n      \"pomegranate\": 957,\n      \"poncho\": 735,\n      \"pool table, billiard table, snooker table\": 736,\n      \"pop bottle, soda bottle\": 737,\n      \"porcupine, hedgehog\": 334,\n      \"pot, flowerpot\": 738,\n      \"potpie\": 964,\n      \"potter's wheel\": 739,\n      \"power drill\": 740,\n      \"prairie chicken, prairie grouse, prairie fowl\": 83,\n      \"prayer rug, prayer mat\": 741,\n      \"pretzel\": 932,\n      \"printer\": 742,\n      \"prison, prison house\": 743,\n      \"proboscis monkey, Nasalis larvatus\": 376,\n      \"projectile, missile\": 744,\n      \"projector\": 745,\n      \"promontory, headland, head, foreland\": 976,\n      \"ptarmigan\": 81,\n      \"puck, hockey puck\": 746,\n      \"puffer, pufferfish, blowfish, globefish\": 397,\n      \"pug, pug-dog\": 254,\n      \"punching bag, punch bag, punching ball, punchball\": 747,\n      \"purse\": 748,\n      \"quail\": 85,\n      \"quill, quill pen\": 749,\n      \"quilt, comforter, comfort, puff\": 750,\n      \"racer, race car, racing car\": 751,\n      \"racket, racquet\": 752,\n      \"radiator\": 753,\n      \"radio telescope, radio reflector\": 755,\n      \"radio, wireless\": 754,\n      \"rain barrel\": 756,\n      \"ram, tup\": 348,\n      \"rapeseed\": 984,\n      \"recreational vehicle, RV, R.V.\": 757,\n      \"red fox, Vulpes vulpes\": 277,\n      \"red wine\": 966,\n      \"red wolf, maned wolf, Canis rufus, Canis niger\": 271,\n      \"red-backed sandpiper, dunlin, Erolia alpina\": 140,\n      \"red-breasted merganser, Mergus serrator\": 98,\n      \"redbone\": 168,\n      \"redshank, Tringa totanus\": 141,\n      \"reel\": 758,\n      \"reflex camera\": 759,\n      \"refrigerator, icebox\": 760,\n      \"remote control, remote\": 761,\n      \"restaurant, eating house, eating place, eatery\": 762,\n      \"revolver, six-gun, six-shooter\": 763,\n      \"rhinoceros beetle\": 306,\n      \"rifle\": 764,\n      \"ringlet, ringlet butterfly\": 322,\n      \"ringneck snake, ring-necked snake, ring snake\": 53,\n      \"robin, American robin, Turdus migratorius\": 15,\n      \"rock beauty, Holocanthus tricolor\": 392,\n      \"rock crab, Cancer irroratus\": 119,\n      \"rock python, rock snake, Python sebae\": 62,\n      \"rocking chair, rocker\": 765,\n      \"rotisserie\": 766,\n      \"rubber eraser, rubber, pencil eraser\": 767,\n      \"ruddy turnstone, Arenaria interpres\": 139,\n      \"ruffed grouse, partridge, Bonasa umbellus\": 82,\n      \"rugby ball\": 768,\n      \"rule, ruler\": 769,\n      \"running shoe\": 770,\n      \"safe\": 771,\n      \"safety pin\": 772,\n      \"saltshaker, salt shaker\": 773,\n      \"sandal\": 774,\n      \"sandbar, sand bar\": 977,\n      \"sarong\": 775,\n      \"sax, saxophone\": 776,\n      \"scabbard\": 777,\n      \"scale, weighing machine\": 778,\n      \"schipperke\": 223,\n      \"school bus\": 779,\n      \"schooner\": 780,\n      \"scoreboard\": 781,\n      \"scorpion\": 71,\n      \"screen, CRT screen\": 782,\n      \"screw\": 783,\n      \"screwdriver\": 784,\n      \"scuba diver\": 983,\n      \"sea anemone, anemone\": 108,\n      \"sea cucumber, holothurian\": 329,\n      \"sea lion\": 150,\n      \"sea slug, nudibranch\": 115,\n      \"sea snake\": 65,\n      \"sea urchin\": 328,\n      \"seashore, coast, seacoast, sea-coast\": 978,\n      \"seat belt, seatbelt\": 785,\n      \"sewing machine\": 786,\n      \"shield, buckler\": 787,\n      \"shoe shop, shoe-shop, shoe store\": 788,\n      \"shoji\": 789,\n      \"shopping basket\": 790,\n      \"shopping cart\": 791,\n      \"shovel\": 792,\n      \"shower cap\": 793,\n      \"shower curtain\": 794,\n      \"siamang, Hylobates syndactylus, Symphalangus syndactylus\": 369,\n      \"sidewinder, horned rattlesnake, Crotalus cerastes\": 68,\n      \"silky terrier, Sydney silky\": 201,\n      \"ski\": 795,\n      \"ski mask\": 796,\n      \"skunk, polecat, wood pussy\": 361,\n      \"sleeping bag\": 797,\n      \"slide rule, slipstick\": 798,\n      \"sliding door\": 799,\n      \"slot, one-armed bandit\": 800,\n      \"sloth bear, Melursus ursinus, Ursus ursinus\": 297,\n      \"slug\": 114,\n      \"snail\": 113,\n      \"snorkel\": 801,\n      \"snow leopard, ounce, Panthera uncia\": 289,\n      \"snowmobile\": 802,\n      \"snowplow, snowplough\": 803,\n      \"soap dispenser\": 804,\n      \"soccer ball\": 805,\n      \"sock\": 806,\n      \"soft-coated wheaten terrier\": 202,\n      \"solar dish, solar collector, solar furnace\": 807,\n      \"sombrero\": 808,\n      \"sorrel\": 339,\n      \"soup bowl\": 809,\n      \"space bar\": 810,\n      \"space heater\": 811,\n      \"space shuttle\": 812,\n      \"spaghetti squash\": 940,\n      \"spatula\": 813,\n      \"speedboat\": 814,\n      \"spider monkey, Ateles geoffroyi\": 381,\n      \"spider web, spider's web\": 815,\n      \"spindle\": 816,\n      \"spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish\": 123,\n      \"spoonbill\": 129,\n      \"sports car, sport car\": 817,\n      \"spotlight, spot\": 818,\n      \"spotted salamander, Ambystoma maculatum\": 28,\n      \"squirrel monkey, Saimiri sciureus\": 382,\n      \"stage\": 819,\n      \"standard poodle\": 267,\n      \"standard schnauzer\": 198,\n      \"starfish, sea star\": 327,\n      \"steam locomotive\": 820,\n      \"steel arch bridge\": 821,\n      \"steel drum\": 822,\n      \"stethoscope\": 823,\n      \"stingray\": 6,\n      \"stinkhorn, carrion fungus\": 994,\n      \"stole\": 824,\n      \"stone wall\": 825,\n      \"stopwatch, stop watch\": 826,\n      \"stove\": 827,\n      \"strainer\": 828,\n      \"strawberry\": 949,\n      \"street sign\": 919,\n      \"streetcar, tram, tramcar, trolley, trolley car\": 829,\n      \"stretcher\": 830,\n      \"studio couch, day bed\": 831,\n      \"stupa, tope\": 832,\n      \"sturgeon\": 394,\n      \"submarine, pigboat, sub, U-boat\": 833,\n      \"suit, suit of clothes\": 834,\n      \"sulphur butterfly, sulfur butterfly\": 325,\n      \"sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita\": 89,\n      \"sundial\": 835,\n      \"sunglass\": 836,\n      \"sunglasses, dark glasses, shades\": 837,\n      \"sunscreen, sunblock, sun blocker\": 838,\n      \"suspension bridge\": 839,\n      \"swab, swob, mop\": 840,\n      \"sweatshirt\": 841,\n      \"swimming trunks, bathing trunks\": 842,\n      \"swing\": 843,\n      \"switch, electric switch, electrical switch\": 844,\n      \"syringe\": 845,\n      \"tabby, tabby cat\": 281,\n      \"table lamp\": 846,\n      \"tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui\": 32,\n      \"tank, army tank, armored combat vehicle, armoured combat vehicle\": 847,\n      \"tape player\": 848,\n      \"tarantula\": 76,\n      \"teapot\": 849,\n      \"teddy, teddy bear\": 850,\n      \"television, television system\": 851,\n      \"tench, Tinca tinca\": 0,\n      \"tennis ball\": 852,\n      \"terrapin\": 36,\n      \"thatch, thatched roof\": 853,\n      \"theater curtain, theatre curtain\": 854,\n      \"thimble\": 855,\n      \"three-toed sloth, ai, Bradypus tridactylus\": 364,\n      \"thresher, thrasher, threshing machine\": 856,\n      \"throne\": 857,\n      \"thunder snake, worm snake, Carphophis amoenus\": 52,\n      \"tick\": 78,\n      \"tiger beetle\": 300,\n      \"tiger cat\": 282,\n      \"tiger shark, Galeocerdo cuvieri\": 3,\n      \"tiger, Panthera tigris\": 292,\n      \"tile roof\": 858,\n      \"timber wolf, grey wolf, gray wolf, Canis lupus\": 269,\n      \"titi, titi monkey\": 380,\n      \"toaster\": 859,\n      \"tobacco shop, tobacconist shop, tobacconist\": 860,\n      \"toilet seat\": 861,\n      \"toilet tissue, toilet paper, bathroom tissue\": 999,\n      \"torch\": 862,\n      \"totem pole\": 863,\n      \"toucan\": 96,\n      \"tow truck, tow car, wrecker\": 864,\n      \"toy poodle\": 265,\n      \"toy terrier\": 158,\n      \"toyshop\": 865,\n      \"tractor\": 866,\n      \"traffic light, traffic signal, stoplight\": 920,\n      \"trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi\": 867,\n      \"tray\": 868,\n      \"tree frog, tree-frog\": 31,\n      \"trench coat\": 869,\n      \"triceratops\": 51,\n      \"tricycle, trike, velocipede\": 870,\n      \"trifle\": 927,\n      \"trilobite\": 69,\n      \"trimaran\": 871,\n      \"tripod\": 872,\n      \"triumphal arch\": 873,\n      \"trolleybus, trolley coach, trackless trolley\": 874,\n      \"trombone\": 875,\n      \"tub, vat\": 876,\n      \"turnstile\": 877,\n      \"tusker\": 101,\n      \"typewriter keyboard\": 878,\n      \"umbrella\": 879,\n      \"unicycle, monocycle\": 880,\n      \"upright, upright piano\": 881,\n      \"vacuum, vacuum cleaner\": 882,\n      \"valley, vale\": 979,\n      \"vase\": 883,\n      \"vault\": 884,\n      \"velvet\": 885,\n      \"vending machine\": 886,\n      \"vestment\": 887,\n      \"viaduct\": 888,\n      \"vine snake\": 59,\n      \"violin, fiddle\": 889,\n      \"vizsla, Hungarian pointer\": 211,\n      \"volcano\": 980,\n      \"volleyball\": 890,\n      \"vulture\": 23,\n      \"waffle iron\": 891,\n      \"walking stick, walkingstick, stick insect\": 313,\n      \"wall clock\": 892,\n      \"wallaby, brush kangaroo\": 104,\n      \"wallet, billfold, notecase, pocketbook\": 893,\n      \"wardrobe, closet, press\": 894,\n      \"warplane, military plane\": 895,\n      \"warthog\": 343,\n      \"washbasin, handbasin, washbowl, lavabo, wash-hand basin\": 896,\n      \"washer, automatic washer, washing machine\": 897,\n      \"water bottle\": 898,\n      \"water buffalo, water ox, Asiatic buffalo, Bubalus bubalis\": 346,\n      \"water jug\": 899,\n      \"water ouzel, dipper\": 20,\n      \"water snake\": 58,\n      \"water tower\": 900,\n      \"weasel\": 356,\n      \"web site, website, internet site, site\": 916,\n      \"weevil\": 307,\n      \"whippet\": 172,\n      \"whiptail, whiptail lizard\": 41,\n      \"whiskey jug\": 901,\n      \"whistle\": 902,\n      \"white stork, Ciconia ciconia\": 127,\n      \"white wolf, Arctic wolf, Canis lupus tundrarum\": 270,\n      \"wig\": 903,\n      \"wild boar, boar, Sus scrofa\": 342,\n      \"window screen\": 904,\n      \"window shade\": 905,\n      \"wine bottle\": 907,\n      \"wing\": 908,\n      \"wire-haired fox terrier\": 188,\n      \"wok\": 909,\n      \"wolf spider, hunting spider\": 77,\n      \"wombat\": 106,\n      \"wood rabbit, cottontail, cottontail rabbit\": 330,\n      \"wooden spoon\": 910,\n      \"wool, woolen, woollen\": 911,\n      \"worm fence, snake fence, snake-rail fence, Virginia fence\": 912,\n      \"wreck\": 913,\n      \"yawl\": 914,\n      \"yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripedium parviflorum\": 986,\n      \"yurt\": 915,\n      \"zebra\": 340,\n      \"zucchini, courgette\": 939\n    },\n    \"layer_norm_eps\": 1e-12,\n    \"length_penalty\": 1.0,\n    \"max_length\": 20,\n    \"min_length\": 0,\n    \"model_type\": \"vit\",\n    \"no_repeat_ngram_size\": 0,\n    \"num_attention_heads\": 12,\n    \"num_beam_groups\": 1,\n    \"num_beams\": 1,\n    \"num_channels\": 3,\n    \"num_hidden_layers\": 12,\n    \"num_return_sequences\": 1,\n    \"output_attentions\": false,\n    \"output_hidden_states\": false,\n    \"output_scores\": false,\n    \"pad_token_id\": null,\n    \"patch_size\": 16,\n    \"prefix\": null,\n    \"problem_type\": null,\n    \"pruned_heads\": {},\n    \"qkv_bias\": true,\n    \"remove_invalid_values\": false,\n    \"repetition_penalty\": 1.0,\n    \"return_dict\": true,\n    \"return_dict_in_generate\": false,\n    \"sep_token_id\": null,\n    \"task_specific_params\": null,\n    \"temperature\": 1.0,\n    \"tie_encoder_decoder\": false,\n    \"tie_word_embeddings\": true,\n    \"tokenizer_class\": null,\n    \"top_k\": 50,\n    \"top_p\": 1.0,\n    \"torch_dtype\": null,\n    \"torchscript\": false,\n    \"transformers_version\": \"4.20.1\",\n    \"typical_p\": 1.0,\n    \"use_bfloat16\": false\n  },\n  \"eos_token_id\": 2,\n  \"is_encoder_decoder\": true,\n  \"length_penalty\": 2.0,\n  \"max_length\": 64,\n  \"model_type\": \"vision-encoder-decoder\",\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 31,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": null,\n  \"vocab_size\": 64000\n}\n\nloading weights file ./m/pytorch_model.bin\nAll model checkpoint weights were used when initializing VisionEncoderDecoderModel.\n\nAll the weights of VisionEncoderDecoderModel were initialized from the model checkpoint at ./m.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use VisionEncoderDecoderModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"##ة في ، من والةةة ،ةة منةة فيةةةة المةة \"ةةةةهةة العةةاةةتةةاتةةهاة\ntensor([[  33,   33,   33,  251,   33,   33,   32,   33,   33,  289,   33,   33,\n          130,   33,   33,  290,   33,   33, 6689,  251,  251,  251,  130,  251,\n          251,  290,  251,  251,  289,  251,  251,   34,  251,  251, 7214,  251,\n          251,   37,  251,  251,   32,  251,  251,  223,  251,  251, 6958,  251,\n          251,  195,  251,  251,  210,  251,  251,  440,  251,  251, 2331,   34,\n           34,   34,  251,   34]], device='cuda:0')\n","output_type":"stream"}]}]}